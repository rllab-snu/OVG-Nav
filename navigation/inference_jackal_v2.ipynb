{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "import sys\n",
    "sys.path.append('/home/navi3/hwing/OVG-Nav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "\n",
    "\n",
    "## eval configs ##\n",
    "parser.add_argument(\"--gpu_list\", type=str, default=\"0\")\n",
    "parser.add_argument(\"--model_gpu\", type=str, default=\"0\")\n",
    "parser.add_argument(\"--sim_gpu\", type=str, default=\"0\")\n",
    "parser.add_argument(\"--max_step\", type=int, default=500)\n",
    "parser.add_argument(\"--save_dir\", type=str, default=\"/home/navi3/hwing/OVG-Nav_inference/result/realworld/0818_vo/test_edge1.0_height_0.88_lastmile5.0_actrot30\")\n",
    "parser.add_argument(\"--seed\", type=int, default=1)\n",
    "parser.add_argument(\"--vis_floorplan\", type=bool, default=True)\n",
    "parser.add_argument(\"--use_oracle\", type=bool, default=False)\n",
    "parser.add_argument(\"--goal_class\", type=int, default=0)\n",
    "parser.add_argument(\"--cm_type\", type=str, default=\"comet\")\n",
    "parser.add_argument('--goal_cat', type=str, default='mp3d_21')\n",
    "\n",
    "\n",
    "## observation configs ##\n",
    "parser.add_argument(\"--front_width\", type=int, default=640)\n",
    "parser.add_argument(\"--front_height\", type=int, default=480)\n",
    "parser.add_argument(\"--front_hfov\", type=float, default=55.58)\n",
    "\n",
    "parser.add_argument(\"--add_panoramic_sensor\", type=bool, default=True)\n",
    "parser.add_argument(\"--panoramic_turn_angle\", type=int, default=90)\n",
    "parser.add_argument(\"--width\", type=int, default=256)\n",
    "parser.add_argument(\"--height\", type=int, default=256)\n",
    "parser.add_argument(\"--hfov\", type=int, default=90)\n",
    "parser.add_argument(\"--pano_width\", type=int, default=1024)\n",
    "parser.add_argument(\"--pano_height\", type=int, default=256)\n",
    "parser.add_argument(\"--sensor_height\", type=float, default=0.88)\n",
    "parser.add_argument(\"--goal_obs_count\", type=int, default=3)\n",
    "\n",
    "parser.add_argument(\"--semantic_sensor\", type=bool, default=False)\n",
    "\n",
    "\n",
    "## agent configs ##\n",
    "parser.add_argument(\"--max_frames\", type=int, default=500)\n",
    "parser.add_argument(\"--sensing_range\", type=float, default=5.0)\n",
    "parser.add_argument(\"--move_forward\", type=float, default=0.25)\n",
    "parser.add_argument(\"--edge_range\", type=float, default=1.0)\n",
    "parser.add_argument(\"--last_mile_range\", type=float, default=5.0)\n",
    "parser.add_argument(\"--act_rot\", type=int, default=30)\n",
    "parser.add_argument(\"--cand_rot\", type=int, default=30)\n",
    "parser.add_argument(\"--success_dist\", type=float, default=1.0)\n",
    "\n",
    "## noise configs ##\n",
    "parser.add_argument('--noisy_rgb', type=bool, default=False, help='use Gaussian noise on RGB')\n",
    "parser.add_argument('--noisy_rgb_multiplier', type=float, default=0.1, help='use Gaussian noise on RGB')\n",
    "parser.add_argument('--noisy_depth', type=bool, default=False, help='use RedwoodDepthNoiseModel')\n",
    "parser.add_argument('--noisy_depth_multiplier', type=float, default=5., help='use RedwoodDepthNoiseModel noise multiplier')\n",
    "parser.add_argument(\"--noise_dir\", type=str, default=\"navigation/noise_models\")\n",
    "parser.add_argument('--noisy_action', type=bool, default=False, help='')\n",
    "parser.add_argument('--noisy_pose', type=bool, default=False, help='')\n",
    "\n",
    "## local navigation configs ##\n",
    "parser.add_argument(\"--map_size_cm\", type=int, default=1200)\n",
    "parser.add_argument(\"--map_resolution\", type=int, default=5)\n",
    "\n",
    "\n",
    "## model configs ##\n",
    "parser.add_argument(\"--detection_model\", type=str, default=\"/home/navi3/hwing/OVG-Nav_inference/modules/detector\")\n",
    "parser.add_argument(\"--segmentation_model\", type=str, default=\"/home/navi3/hwing/OVG-Nav_inference/modules/detector/rednet_mp3d.pth\")\n",
    "parser.add_argument(\"--free_space_model\", type=str, default=\"/home/navi3/hwing/OVG-Nav_inference/modules/free_space_model/ckpts/split_lr0.001_0227_range_1.0/best_model_1.pth\")\n",
    "parser.add_argument(\"--CLIP_model\", type=str, default=\"/home/navi3/hwing/OVG-Nav_inference/modules/comet_relation/clip-vit-base-patch32/ViT-B-32.pt\")\n",
    "parser.add_argument(\"--COMET_model\", type=str, default=\"/home/navi3/hwing/OVG-Nav_inference/modules/comet_relation/comet-atomic_2020_BART\")\n",
    "\n",
    "# parser.add_argument(\"--value_model\", type=str, default='/data1/hwing/Projects/offline_objgoal/goal_dist_pred/logs/cm_0610/0610_v2_1_use_cm_maxdist30.0_lr0.001/model_25.pth')\n",
    "# parser.add_argument(\"--value_model\", type=str, default='/data1/hwing/Projects/offline_objgoal/goal_dist_pred/logs/cm_0616/0616_combv2_modelv2_1_use_cm_maxdist30.0_lr0.0001/model_20.pth')\n",
    "parser.add_argument(\"--value_model\", type=str, default='/home/navi3/hwing/OVG-Nav_inference/goal_dist_pred/models/16-56_mp3d21_edge1v1.12_panov8_layer10_hidden512_epoch_6_goalscore_w_adjmtx_valueloss1.0_adjloss100.0_adjsimlos0.0_signloss0.0_use_cm_maxdist30.0_lr0.001/model.pth')\n",
    "parser.add_argument('--vis_feat_dim', default=512, type=int)\n",
    "parser.add_argument('--gcn_layers', default=10, type=int)\n",
    "parser.add_argument('--use_cm_score', default=True, type=bool)\n",
    "\n",
    "\n",
    "## VO model configs ##\n",
    "parser.add_argument(\"--use_vo\", type=bool, default=True)\n",
    "parser.add_argument('--max_depth', type=float, default=5., help='maximum depth value')\n",
    "parser.add_argument('--min_depth', type=float, default=0.1, help='minimum depth value')\n",
    "parser.add_argument('--KM_resize', type=int, nargs='+', default=[640, 480],\n",
    "        help='Resize the input image before running inference. If two numbers, '\n",
    "             'resize to the exact dimensions, if one number, resize the max '\n",
    "             'dimension, if -1, do not resize')\n",
    "parser.add_argument('--KM_superglue', choices={'indoor', 'outdoor'}, default='indoor', help='SuperGlue weights')\n",
    "parser.add_argument('--KM_max_keypoints', type=int, default=1024, help='Maximum number of keypoints detected by Superpoint' ' (\\'-1\\' keeps all keypoints)')\n",
    "parser.add_argument('--KM_keypoint_threshold', type=float, default=0.005, help='SuperPoint keypoint detector confidence threshold')\n",
    "parser.add_argument('--KM_nms_radius', type=int, default=4, help='SuperPoint Non Maximum Suppression (NMS) radius' ' (Must be positive)')\n",
    "parser.add_argument('--KM_sinkhorn_iterations', type=int, default=20, help='Number of Sinkhorn iterations performed by SuperGlue')\n",
    "parser.add_argument('--KM_match_threshold', type=float, default=0.2, help='SuperGlue match threshold')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_list\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from enum import Enum\n",
    "if '/opt/ros/kinetic/lib/python2.7/dist-packages' in sys.path:\n",
    "    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import cv2\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import quaternion\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "import skimage\n",
    "\n",
    "_barrier = None\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "\n",
    "from utils.graph_utils.graph_pano_cs import GraphMap\n",
    "from utils.obj_category_info import assign_room_category, obj_names_det as obj_names, gibson_goal_obj_names, mp3d_goal_obj_names, room_names, mp3d_room_names, d3_40_colors_rgb, rednet_obj_names\n",
    "\n",
    "\n",
    "from modules.detector.detector_mask import Detector\n",
    "from modules.detector.rednet_semantic_prediction import SemanticPredRedNet\n",
    "from modules.free_space_model.inference import FreeSpaceModel\n",
    "from modules.comet_relation.inference import CommonSenseModel\n",
    "from modules.visual_odometry.keypoint_matching import KeypointMatching\n",
    "from modules.value_estimation.model_value_graph_0607 import TopoGCN_v8_pano_goalscore as ValueModel\n",
    "\n",
    "\n",
    "from navigation.validity_func.map_builder import build_mapper\n",
    "from navigation.validity_func.fmm_planner import FMMPlanner\n",
    "from validity_func.local_nav import LocalAgent\n",
    "from validity_func.validity_utils import (\n",
    "    get_relative_location,\n",
    "    get_sim_location,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.7.10 (default, Feb 26 2021, 18:47:35) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "from navigation.navi_controller import Controller\n",
    "controller = Controller()\n",
    "controller.act_rot = args.act_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyrealsense2 as rs\n",
    "# frames = controller.pipeline.wait_for_frames()\n",
    "# align = rs.align(rs.stream.color)\n",
    "# aligned_frames = align.process(frames)\n",
    "\n",
    "# depth_frame = aligned_frames.get_depth_frame()\n",
    "# color_frame = aligned_frames.get_color_frame() \n",
    "\n",
    "# depth_frame = controller.decimation.process(depth_frame)\n",
    "# depth_frame = controller.depth_to_disparity.process(depth_frame)\n",
    "# depth_frame = controller.spatial.process(depth_frame)\n",
    "# depth_frame = controller.disparity_to_depth.process(depth_frame)\n",
    "# # depth_frame = controller.hole_filling.process(depth_frame)\n",
    "\n",
    "# color_array=np.array(color_frame.get_data())#set_color(np.array(color_frame.get_data()))\n",
    "# depth_array=np.array(depth_frame.get_data())\n",
    "\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(color_array)\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(depth_array)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_COI = [\n",
    "        56,  # chair\n",
    "        57,  # couch\n",
    "        58,  # potted plant\n",
    "        59,  # bed\n",
    "        61,  # toilet\n",
    "        62,  # tv\n",
    "        60,  # dining table\n",
    "        63,  # laptop\n",
    "        68,  # microwave\n",
    "        69,  # oven\n",
    "        71,  # sink\n",
    "        72,  # refrigerator\n",
    "        74,  # clock\n",
    "        75,  # vase\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUNNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner:\n",
    "    def __init__(self, args, COI, data_type='infer'):\n",
    "        self.args = args\n",
    "        self._sim_settings = sim_settings.copy()\n",
    "        self.dataset = dataset\n",
    "        self.dataset_info = None\n",
    "        self.gt_planner = None\n",
    "        self.data_type = data_type\n",
    "\n",
    "        self.det_COI = COI\n",
    "        self.obj_names = obj_names\n",
    "        if args.dataset == 'mp3d':\n",
    "            self.goal_obj_names = mp3d_goal_obj_names\n",
    "        elif args.dataset == 'gibson':\n",
    "            self.goal_obj_names = gibson_goal_obj_names\n",
    "        # self.sge_th = args.sge_th\n",
    "        if self.args.goal_cat == 'mp3d_21':\n",
    "            self.goal_obj_names = rednet_obj_names\n",
    "\n",
    "        self.pix_num = args.width*args.height\n",
    "        self.cand_angle = np.arange(-120, 240, args.cand_rot)\n",
    "        self.cand_angle_bias = list(self.cand_angle).index(0) # 0 degree is the center\n",
    "        self.edge_range = args.edge_range\n",
    "        self.last_mile_range = args.last_mile_range\n",
    "        self.goal_det_dist = args.success_dist - args.move_forward\n",
    "        self.goal_obs_consistency_th = args.goal_obs_count # number of time steps that the goal is visible for the goal to be considered as correctly detected\n",
    "\n",
    "        self.vo_height = args.front_height\n",
    "        self.vo_width = args.front_width\n",
    "        self.vo_hfov = args.front_hfov\n",
    "\n",
    "        self.height = args.height\n",
    "        self.width = args.width\n",
    "\n",
    "        self.pano_width = args.pano_width\n",
    "        self.pano_height = args.pano_height\n",
    "\n",
    "        self.hfov = args.hfov\n",
    "        self.camera_height = args.sensor_height\n",
    "\n",
    "        self.step_size = args.move_forward\n",
    "        self.follower_goal_radius = 0.75 * self.step_size\n",
    "        self.act_rot = args.act_rot\n",
    "        self.cand_rot_angle = args.cand_rot\n",
    "        self.rot_num = len(self.cand_angle)\n",
    "        self.max_local_action_trial = 50\n",
    "        self.max_step = args.max_step\n",
    "\n",
    "        # self.vo_pred_model = VO_prediction(args.vo_config)\n",
    "        self.depth_scale = np.iinfo(np.uint16).max\n",
    "\n",
    "        self.goal_cat = args.goal_cat\n",
    "        if args.goal_cat == 'mp3d':\n",
    "            self.detector = Detector(args, self.det_COI)\n",
    "        elif args.goal_cat == 'mp3d_21':\n",
    "            self.detector = SemanticPredRedNet(args)\n",
    "        self.free_space_model = FreeSpaceModel(args)\n",
    "        self.common_sense_model = CommonSenseModel(args)\n",
    "        # self.noisy_pose = args.noisy_pose\n",
    "        self.vo_model = KeypointMatching(args)\n",
    "\n",
    "        self.value_model = ValueModel(self.args)\n",
    "        # self.value_model = nn.DataParallel(self.value_model).cuda()\n",
    "        # self.value_model.load_state_dict(torch.load(self.args.value_model))\n",
    "        state_dict = torch.load(self.args.value_model)\n",
    "        new_state_dict = {}\n",
    "        for k, v in state_dict.items():\n",
    "            if 'module' in k:\n",
    "                k = k.replace('module.', '')\n",
    "            new_state_dict[k] = v\n",
    "        self.value_model.load_state_dict(new_state_dict)\n",
    "        self.value_model = self.value_model.to(f'cuda:{args.model_gpu}')\n",
    "        self.value_model.eval()\n",
    "\n",
    "        # self.local_navi_module = LocalNavigation(self.args, self.vo_model)\n",
    "        self.local_agent = LocalAgent(self.args)\n",
    "        self.local_mapper = build_mapper(self.args)\n",
    "\n",
    "\n",
    "\n",
    "        self.vis_floorplan = args.vis_floorplan\n",
    "        self.use_oracle = args.use_oracle\n",
    "        self.cm_type = args.cm_type  ### 'comet or mp3d'\n",
    "\n",
    "        self.cand_node_frame = get_range_cand_nodes(int(args.sensing_range / self.edge_range), self.edge_range)\n",
    "\n",
    "        ## -- localization template -- ##\n",
    "\n",
    "        self.rot_grid = {'move_forward': [], 'turn_left': [], 'turn_right': []}\n",
    "        rot_angle = 5 * np.pi / 180.\n",
    "        self.localize_rot_num = 7\n",
    "        self.rot_grid_headings = {'move_forward': [], 'turn_left': [], 'turn_right': []}\n",
    "        for i in range(-3, 4):\n",
    "            angle_0 = rot_angle * i\n",
    "            self.rot_grid['move_forward'].append(torch.FloatTensor(\n",
    "                [[np.cos(angle_0), -np.sin(angle_0), 0],\n",
    "                 [np.sin(angle_0), np.cos(angle_0), 0]]))\n",
    "            self.rot_grid_headings['move_forward'].append(-angle_0)\n",
    "\n",
    "            angle_1 = rot_angle * i - self.act_rot * np.pi / 180\n",
    "            self.rot_grid['turn_left'].append(torch.FloatTensor(\n",
    "                [[np.cos(angle_1), -np.sin(angle_1), 0],\n",
    "                 [np.sin(angle_1), np.cos(angle_1), 0]]))\n",
    "            self.rot_grid_headings['turn_left'].append(-angle_1)\n",
    "\n",
    "            angle_2 = rot_angle * i + self.act_rot * np.pi / 180\n",
    "            self.rot_grid['turn_right'].append(torch.FloatTensor(\n",
    "                [[np.cos(angle_2), -np.sin(angle_2), 0],\n",
    "                 [np.sin(angle_2), np.cos(angle_2), 0]]))\n",
    "            self.rot_grid_headings['turn_right'].append(-angle_2)\n",
    "        local_map_size = self.local_mapper.gt_map.shape[0]\n",
    "        self.local_map_size = local_map_size\n",
    "        self.rot_grid['move_forward'] = torch.stack(self.rot_grid['move_forward'])\n",
    "        self.rot_grid['move_forward'] = F.affine_grid(self.rot_grid['move_forward'], torch.Size((self.localize_rot_num, 1, local_map_size, local_map_size)))\n",
    "        self.rot_grid['turn_left'] = torch.stack(self.rot_grid['turn_left'])\n",
    "        self.rot_grid['turn_left'] = F.affine_grid(self.rot_grid['turn_left'], torch.Size((self.localize_rot_num, 1, local_map_size, local_map_size)))\n",
    "        self.rot_grid['turn_right'] = torch.stack(self.rot_grid['turn_right'])\n",
    "        self.rot_grid['turn_right'] = F.affine_grid(self.rot_grid['turn_right'], torch.Size((self.localize_rot_num, 1, local_map_size, local_map_size)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def save_rgbd_video(self, rgb_list, depth_list, save_dir, panoramic=False):\n",
    "        if panoramic:\n",
    "            width = self.pano_width\n",
    "            height = self.pano_height\n",
    "            rgb_name = 'pano_rgb'\n",
    "            depth_name = 'pano_depth'\n",
    "        else:\n",
    "            width = self.vo_width\n",
    "            height = self.vo_height\n",
    "            rgb_name = 'rgb'\n",
    "            depth_name = 'depth'\n",
    "\n",
    "        video = cv2.VideoWriter(f'{save_dir}/{rgb_name}.avi', cv2.VideoWriter_fourcc(*'XVID'), 5,\n",
    "                                (width, height))\n",
    "        for image in rgb_list:\n",
    "            image = cv2.cvtColor((image[:, :, :3] / 255.).astype(np.float32), cv2.COLOR_RGB2BGR)\n",
    "            video.write((image * 255).astype(np.uint8))\n",
    "        video.release()\n",
    "\n",
    "        video = cv2.VideoWriter(f'{save_dir}/{depth_name}.avi', cv2.VideoWriter_fourcc(*'XVID'), 5,\n",
    "                                (width, height), isColor=False)\n",
    "        for depth_obs in depth_list:\n",
    "            depth_obs = (np.clip(depth_obs, 0.1, 10.) / 10.).astype(np.float32)\n",
    "            depth_obs = (depth_obs * self.depth_scale).astype(np.uint16) / self.depth_scale\n",
    "            depth_obs = (depth_obs * 255).astype(np.uint8)\n",
    "            video.write(depth_obs)\n",
    "        video.release()\n",
    "\n",
    "    def save_video(self, frame_list, save_dir):\n",
    "        if not os.path.exists(save_dir): os.makedirs(save_dir)\n",
    "\n",
    "        width = np.shape(frame_list[0])[1]\n",
    "        height = np.shape(frame_list[0])[0]\n",
    "\n",
    "        video = cv2.VideoWriter(f'{save_dir}/graph.avi', cv2.VideoWriter_fourcc(*'XVID'), 5,\n",
    "                                (width, height))\n",
    "        for image in frame_list:\n",
    "            image = cv2.cvtColor((image[:, :, :3] / 255.).astype(np.float32), cv2.COLOR_RGB2BGR)\n",
    "            video.write((image * 255).astype(np.uint8))\n",
    "        video.release()\n",
    "\n",
    "    def make_total_frame(self, rgb, depth, graph, local_map, pano_rgb, info, frame_num=None):\n",
    "        rh, rw = np.shape(rgb)[:2]\n",
    "        rh, rw = int(rh / 2), int(rw / 2)\n",
    "        small_rgb = cv2.resize(rgb, (rw, rh))\n",
    "        small_depth = cv2.resize(depth, (rw, rh))\n",
    "        small_depth = ((np.clip(small_depth, 0.1, 10.) / 10.) * 255).astype(np.uint8)\n",
    "        gh, gw = np.shape(graph)[:2]\n",
    "        gh, gw = int(rw * 2 * gh / gw), rw * 2\n",
    "        ph, pw = np.shape(pano_rgb)[:2]\n",
    "        ph, pw = int(rw / 2), rw * 2\n",
    "        small_pano_rgb = cv2.resize(pano_rgb.astype(np.uint8), (pw, ph))\n",
    "\n",
    "        lh, lw = np.shape(local_map)[:2]\n",
    "        local_map = cv2.flip(local_map, 1)\n",
    "        # lh, lw = int(lh/2), int(lw/2)\n",
    "        # local_map = cv2.resize(local_map, (lw, lh))\n",
    "\n",
    "        small_graph = cv2.resize(graph, (gw, gh))\n",
    "        max_h = rh + ph + gh + lh\n",
    "        max_w = max(rw*2, gw, lw, pw)\n",
    "\n",
    "        frame = np.zeros([max_h, max_w, 3])\n",
    "        frame[:rh, :rw, :] = small_rgb[:, :, :3]\n",
    "        frame[:rh, rw:rw*2, :] = np.tile(small_depth[:, :, np.newaxis], [1, 1, 3])\n",
    "        frame[rh:rh+ph, :pw, :] = small_pano_rgb[:, :, :3]\n",
    "        frame[rh+ph:rh+ph+gh, :gw, ] = small_graph\n",
    "        frame[rh+ph+gh:, :lw, :] = local_map[:, :, :3]\n",
    "        frame = frame.astype(np.uint8)\n",
    "\n",
    "\n",
    "        ## text\n",
    "        text1 = \"Target object goal: {}   Mode: {}\".format(info['target_goal'], info['mode'])\n",
    "        text2 = \"Step: {}   Position: {}\".format(info['step'], info['cur_position'])\n",
    "        font_color = (255, 255, 255)\n",
    "        text_size, _ = cv2.getTextSize(text1, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
    "        # text_position1 = (int((frame.shape[1] - text_size[0]) / 2), frame.shape[0] + text_size[1] * 2 + 10)\n",
    "        # text_position2 = (int((frame.shape[1] - text_size[0]) / 2), frame.shape[0] + text_size[1] * 2 + 25)\n",
    "        text_position1 = (10, frame.shape[0] + text_size[1] * 2 + 10)\n",
    "        text_position2 = (10, frame.shape[0] + text_size[1] * 2 + 25)\n",
    "        canvas_height = frame.shape[0] + text_size[1] * 2 + 40\n",
    "        canvas_width = frame.shape[1]\n",
    "        canvas = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)\n",
    "        canvas[:frame.shape[0], :] = frame\n",
    "        # canvas = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)\n",
    "        frame2 = cv2.putText(canvas, text1, text_position1, cv2.FONT_HERSHEY_SIMPLEX, 0.4, font_color, 1, cv2.LINE_AA)\n",
    "        frame2 = cv2.putText(canvas, text2, text_position2, cv2.FONT_HERSHEY_SIMPLEX, 0.4, font_color, 1, cv2.LINE_AA)\n",
    "        \n",
    "        if not frame_num is None:\n",
    "            if not os.path.exists('epi_{0:02d}'.format(self.epi_num)):\n",
    "                os.makedirs('epi_{0:02d}'.format(self.epi_num))\n",
    "            plt.imsave('epi_{0:02d}/frame_{1:04d}.png'.format(self.epi_num, frame_num), frame2)\n",
    "        return frame2\n",
    "\n",
    "\n",
    "\n",
    "    def panoramic_obs(self, obs, semantic=False):\n",
    "\n",
    "        rgb_panoramic = np.zeros([self.pano_height, self.pano_width, 3]).astype(int)\n",
    "        # depth_panoramic = np.zeros([self.pano_height, self.pano_width])\n",
    "        if semantic:\n",
    "            semantic_panoramic = np.zeros([self.pano_height, self.pano_width]).astype(int)\n",
    "\n",
    "        for i, rot in enumerate([ '270', '0', '90', '180']):\n",
    "\n",
    "            rgb_panoramic[:, i * self.width:(i + 1) * self.width, :] = obs[f'rgb_{rot}'][:, :, :3]   # 320 - 320* np.tan(30/180*np.pi) / np.tan(35/180*np.pi) = 56\n",
    "            # depth_panoramic[:, i * self.width:(i + 1) * self.width] = obs[f'depth_{rot}']\n",
    "\n",
    "        return {\n",
    "            'rgb_panoramic': rgb_panoramic,\n",
    "            # 'depth_panoramic': depth_panoramic\n",
    "        }\n",
    "\n",
    "    def init_commonsense_candidate_room(self, goal_names, candidate_names):\n",
    "        goal_category_room = {}\n",
    "        goal_category_room_feat = {}\n",
    "        goal_category_room_score = {}\n",
    "\n",
    "        cand_category_room = {}\n",
    "        cand_category_room_feat = {}\n",
    "        cand_category_room_score = {}\n",
    "        cand_room_feat = self.common_sense_model.clip.get_text_feat(candidate_names).type(torch.float32)\n",
    "        for i, goal_name in enumerate(goal_names):\n",
    "            pred_words = self.common_sense_model.gen_pred_words(self.goal_obj_names[i] + ' in an indoor space',\n",
    "                                                                num_generate=10)\n",
    "            # pred_words = pred_words[0]\n",
    "            pred_words_feat = self.common_sense_model.clip.get_text_feat(pred_words).type(torch.float32)\n",
    "\n",
    "            goal_category_room[goal_name] = pred_words\n",
    "            goal_category_room_feat[goal_name] = pred_words_feat.cpu()\n",
    "            goal_category_room_score[goal_name] = np.ones_like(pred_words).astype(float)\n",
    "\n",
    "            value, indice = torch.max(\n",
    "                self.common_sense_model.clip.get_sim_from_feats(cand_room_feat, pred_words_feat, normalize=True).type(\n",
    "                    torch.float32),\n",
    "                dim=0)\n",
    "            topk = torch.topk(value, k=len(candidate_names), largest=True).indices.detach().cpu().numpy()\n",
    "            cand_category_room[goal_name] = [candidate_names[i] for i in topk]\n",
    "            cand_category_room_feat[goal_name] = torch.stack([cand_room_feat[i].detach().cpu() for i in topk])\n",
    "            cand_category_room_score[goal_name] = np.array([value[i].detach().cpu().numpy() for i in topk])\n",
    "\n",
    "        return goal_category_room, goal_category_room_feat, goal_category_room_score, cand_category_room, cand_category_room_feat, cand_category_room_score\n",
    "\n",
    "\n",
    "    def node_value_by_obj_dist(self, dist, max_dist=15.0):\n",
    "        return max(1 - dist / max_dist, 0)\n",
    "    \n",
    "    def get_vis_grid_pose(self, pose):\n",
    "        grid_size = (0.02, 0.02)\n",
    "        lower_bound_x = -10\n",
    "        lower_bound_y = -10\n",
    "        if len(pose) == 3:\n",
    "            pose = np.array(pose)\n",
    "            grid_x = int((pose[0] - lower_bound_y) / grid_size[1])\n",
    "            grid_y = int((pose[2] - lower_bound_x) / grid_size[0])\n",
    "            \n",
    "        elif len(pose) == 2:\n",
    "            grid_x = int((pose[0] - lower_bound_y) / grid_size[1])\n",
    "            grid_y = int((pose[1] - lower_bound_x) / grid_size[0])\n",
    "            \n",
    "        return (grid_x, grid_y)\n",
    "\n",
    "    def vis_topdown_graph_map(self, vis_map, graph_map, vis_obj_score=None, curr_node_id=None, curr_goal_node_id=None,\n",
    "                              bias_position=None, curr_goal_position=None, visited_positions=None):\n",
    "        node_list = list(graph_map.node_by_id.values())\n",
    "\n",
    "        for edge in list(graph_map.edges):\n",
    "            if not edge.draw:\n",
    "                pos1 = np.array(edge.nodes[0].pos) if edge.nodes[0].vis_pos is None else np.array(edge.nodes[0].vis_pos)\n",
    "                pos2 = np.array(edge.nodes[1].pos) if edge.nodes[1].vis_pos is None else np.array(edge.nodes[1].vis_pos)\n",
    "                node_grid1 = self.get_vis_grid_pose(pos1 + bias_position)\n",
    "                node_grid2 = self.get_vis_grid_pose(pos2 + bias_position)\n",
    "                vis_map = cv2.line(vis_map, node_grid1, node_grid2, (0, 64, 64), 5)\n",
    "                edge.draw = True\n",
    "\n",
    "        cm_scores = []\n",
    "        for node in node_list:\n",
    "            cm_scores.append(node.cm_score)\n",
    "        cm_scores = np.array(cm_scores)\n",
    "        cm_scores = np.exp(cm_scores) / np.sum(np.exp(cm_scores))\n",
    "\n",
    "        for idx, node in enumerate(node_list):\n",
    "\n",
    "            node_pos = np.array(node.pos) if node.vis_pos is None else np.array(node.vis_pos)\n",
    "\n",
    "            node_grid = self.get_vis_grid_pose(node_pos + bias_position)\n",
    "            if vis_obj_score is not None:\n",
    "                color = (0, 255, 0)\n",
    "                cand_color = (np.array((0, 0, 255)) * cm_scores[idx]).astype(int)\n",
    "                cand_color = tuple([cand_color[i].item() for i in range(3)])\n",
    "                goal_color = (255, 255, 0)\n",
    "            else:\n",
    "                color = (0, 255, 0)\n",
    "                cand_color = (0, 0, 255)\n",
    "                goal_color = (255, 255, 0)\n",
    "            if node.visited:\n",
    "                if node.nodeid == curr_node_id:\n",
    "                    vis_map = cv2.circle(vis_map, node_grid, 10, (255,0,0), -1)\n",
    "                else:\n",
    "                    vis_map = cv2.circle(vis_map, node_grid, 10, color, -1)\n",
    "            elif node.nodeid == curr_goal_node_id:\n",
    "                vis_map = cv2.circle(vis_map, node_grid, 10, goal_color, -1)\n",
    "            else:\n",
    "                vis_map = cv2.circle(vis_map, node_grid, 10, cand_color, -1)\n",
    "\n",
    "            node.draw = True\n",
    "\n",
    "        if visited_positions is not None:\n",
    "            for pos in visited_positions:\n",
    "                node_grid = self.get_vis_grid_pose(pos + bias_position)\n",
    "                vis_map = cv2.circle(vis_map, node_grid, 5, (125, 0, 0), -1)\n",
    "\n",
    "        if curr_goal_position is not None:\n",
    "            node_grid = self.get_vis_grid_pose(curr_goal_position + bias_position)\n",
    "            vis_map = cv2.rectangle(vis_map, (node_grid[0] - 8, node_grid[1] - 8), (node_grid[0] + 8, node_grid[1] + 8),\n",
    "                                    (255, 255, 0), -1)\n",
    "\n",
    "        return vis_map\n",
    "\n",
    "    def vis_pos_on_topdown_map(self, pos, vis_map, color=(255, 0, 0)):\n",
    "        vis_map = vis_map.copy()\n",
    "        node_grid = self.get_vis_grid_pose(pos)\n",
    "        vis_map = cv2.rectangle(vis_map, (node_grid[0] - 8, node_grid[1] - 8), (node_grid[0] + 8, node_grid[1] + 8),\n",
    "                                color, -1)\n",
    "        return vis_map\n",
    "\n",
    "    def save_viewpoint_on_topdown_map(self, save_dir=None, vis_map=None, bias_position=None, curr_position=None, curr_goal_position=None, result=None):\n",
    "\n",
    "        mask = np.repeat(np.sum(self.cur_graph_map, axis=2).astype(bool)[:,:,np.newaxis], 3, axis=2)\n",
    "        vis_map[mask] = cv2.addWeighted(vis_map, 0.0, self.cur_graph_map, 1.0, 0)[mask]\n",
    "\n",
    "        if curr_position is not None:\n",
    "            node_grid = self.get_vis_grid_pose(curr_position + bias_position)\n",
    "            vis_map = cv2.rectangle(vis_map, (node_grid[0] - 8, node_grid[1] - 8), (node_grid[0] + 8, node_grid[1] + 8),\n",
    "                                    (255, 0, 0), -1)\n",
    "        if curr_goal_position is not None:\n",
    "            node_grid = self.get_vis_grid_pose(curr_goal_position + bias_position)\n",
    "            vis_map = cv2.rectangle(vis_map, (node_grid[0] - 8, node_grid[1] - 8), (node_grid[0] + 8, node_grid[1] + 8),\n",
    "                                    (255, 255, 0), -1)\n",
    "\n",
    "        if result is not None:\n",
    "            success = 'SUCCESS' if result['success'] == 1 else 'FAIL'\n",
    "            txt = 'goal: {}, success: {}, path length: {:.4f}, actions {}'.format(result['goal object'], success,\n",
    "                                                                                  result['path_length'],\n",
    "                                                                                  result['action step'])\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 1\n",
    "            color = (255, 255, 255)\n",
    "            thickness = 2\n",
    "            text_size = cv2.getTextSize(txt, font, font_scale, thickness)[0]\n",
    "            text_position = (10, vis_map.shape[0] + text_size[1] * 2 + 10)\n",
    "            canvas_height = vis_map.shape[0] + text_size[1] * 2 + 40\n",
    "            canvas_width = vis_map.shape[1]\n",
    "            canvas = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)\n",
    "            canvas[:vis_map.shape[0], :] = vis_map\n",
    "            canvas = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)\n",
    "            cv2.putText(canvas, txt, text_position, font, font_scale, color, thickness)\n",
    "            cv2.imwrite(save_dir, canvas)\n",
    "        else:\n",
    "            plt.imsave(save_dir, vis_map)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def vis_topdown_map_with_captions(self, graph_map, curr_node=None, curr_goal_node=None,\n",
    "                                      bias_position=None, curr_position=None, curr_goal_position=None,\n",
    "                                      vis_goal_obj_score=None, vis_obj=None,\n",
    "                                      visited_positions=None):\n",
    "        vis_map = self.cur_graph_map\n",
    "\n",
    "        curr_node_id, curr_goal_node_id = None, None\n",
    "        if curr_node is not None:\n",
    "            curr_node_id = curr_node.nodeid\n",
    "        if curr_goal_node is not None:\n",
    "            curr_goal_node_id = curr_goal_node.nodeid\n",
    "        vis_map = self.vis_topdown_graph_map(vis_map, graph_map, vis_obj_score=vis_goal_obj_score,\n",
    "                                                curr_node_id=curr_node_id, curr_goal_node_id=curr_goal_node_id,\n",
    "                                                bias_position=bias_position,\n",
    "                                                visited_positions=visited_positions)\n",
    "\n",
    "        self.cur_graph_map = vis_map\n",
    "        mask = np.repeat(np.sum(self.cur_graph_map, axis=2).astype(bool)[:,:,np.newaxis], 3, axis=2)\n",
    "        self.base_map[mask] = cv2.addWeighted(self.base_map, 0., self.cur_graph_map, 1.0, 0)[mask]\n",
    "\n",
    "        if curr_position is not None:\n",
    "            vis_map = self.vis_pos_on_topdown_map(curr_position + bias_position, self.base_map)\n",
    "        if curr_goal_position is not None:\n",
    "            vis_map = self.vis_pos_on_topdown_map(curr_goal_position + bias_position, vis_map, color=(255, 255, 0))\n",
    "\n",
    "\n",
    "\n",
    "        return vis_map\n",
    "\n",
    "    def dist_euclidean_floor(self, pos1, pos2):\n",
    "        return np.sqrt((pos1[0] - pos2[0]) ** 2 + (pos1[2] - pos2[2]) ** 2)\n",
    "    \n",
    "    def get_vo_relative_camera_pose(self, prev_rgb, prev_depth, curr_rgb, action, cur_rotation, prev_local_map, curr_local_map, initial_guess=None):\n",
    "        # if initial_guess is None:\n",
    "        #     initial_guess = self.vo_model.get_extrinsic_guess_from_action(action)\n",
    "\n",
    "\n",
    "        curr_map = torch.Tensor(curr_local_map).unsqueeze(0).unsqueeze(0)\n",
    "        if action == 'move_forward':\n",
    "            unit_vec = -np.array([np.sin(cur_rotation[1]), 0, np.cos(cur_rotation[1])])\n",
    "            cand_pos = self.cur_position + unit_vec * self.step_size\n",
    "            cand_pose_for_map = (cand_pos[0], cand_pos[2], cur_rotation[1])\n",
    "            cand_pose_on_grid_map_cm = self.local_mapper.get_mapper_pose_from_sim_pose(cand_pose_for_map, (\n",
    "                                        self.cur_position[0], self.cur_position[2], 0))\n",
    "            cand_pose_on_grid_map = self.local_mapper.get_map_grid_from_sim_pose_cm(cand_pose_on_grid_map_cm)\n",
    "            prev_map = self.crop_and_pad(torch.Tensor(prev_local_map), cand_pose_on_grid_map[0], cand_pose_on_grid_map[1])\n",
    "            prev_map = prev_map.unsqueeze(0).unsqueeze(0)\n",
    "        else:\n",
    "            prev_map = torch.Tensor(prev_local_map).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "        rot_filter = F.grid_sample(curr_map.repeat(self.localize_rot_num, 1, 1, 1), self.rot_grid[action])\n",
    "        localize = F.conv2d(prev_map, rot_filter, padding=3)\n",
    "        cand_map_idx = np.unravel_index(np.argmax(localize), localize.shape)\n",
    "\n",
    "        if torch.max(localize) == 0:\n",
    "            initial_guess = self.vo_model.get_extrinsic_guess_from_action(action)\n",
    "        else:\n",
    "            rot_guess = np.array([0, self.rot_grid_headings[action][cand_map_idx[1]], 0]).astype(np.float32)\n",
    "\n",
    "            if action == 'move_forward':\n",
    "                cand_map_pos_idx = (cand_pose_on_grid_map[1] + cand_map_idx[3] - 4, cand_pose_on_grid_map[0] + cand_map_idx[2] - 4)\n",
    "            else:\n",
    "                cand_map_pos_idx = (int(self.local_map_size/2) + cand_map_idx[3] - 4, int(self.local_map_size/2) + cand_map_idx[2] - 4)\n",
    "            pos_guess = self.local_mapper.get_sim_pose_from_mapper_coords(cand_map_pos_idx, (0,0,0), rot_guess)\n",
    "\n",
    "            initial_guess = {\n",
    "                'tvec': pos_guess,\n",
    "                'rvec': rot_guess\n",
    "            }\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        est_pos_diff, est_rot_diff, keypoint_est_success = self.vo_model.get_relative_camera_pose(\n",
    "                                                            prev_rgb, prev_depth, curr_rgb, initial_guess, rot_vec=True)\n",
    "\n",
    "        # ## -- transform to habitat coordinate -- ##\n",
    "        # est_pos_diff[2] = -est_pos_diff[2]\n",
    "        # est_pos_diff[1] = -est_pos_diff[1]\n",
    "\n",
    "        rot = R.from_rotvec(cur_rotation)\n",
    "        rot.as_matrix()\n",
    "        est_pos_diff = rot.apply(est_pos_diff)\n",
    "\n",
    "\n",
    "        return est_pos_diff, est_rot_diff, keypoint_est_success\n",
    "\n",
    "\n",
    "    def get_dirc_imgs_from_pano(self, pano_img, num_imgs=12):\n",
    "        pw, ph = self.pano_width, self.pano_height\n",
    "\n",
    "        width_bias = int(1 / (self.rot_num * 2) * pw)\n",
    "        width_half = int(ph / 2)\n",
    "\n",
    "        # split the panorama into 12 square images with even angles\n",
    "        dirc_imgs = []\n",
    "        for i in range(num_imgs):\n",
    "            angle = i * 360 / num_imgs\n",
    "            x = int(pw * (angle / 360)) + width_bias\n",
    "            start_w = x - width_half\n",
    "            end_w = x + width_half\n",
    "\n",
    "            if start_w < 0:\n",
    "                dirc_img = np.concatenate((pano_img[:, start_w:], pano_img[:, :end_w]), axis=1)\n",
    "            elif end_w > self.pano_width:\n",
    "                dirc_img = np.concatenate((pano_img[:, start_w:], pano_img[:, :end_w - self.pano_width]), axis=1)\n",
    "            else:\n",
    "                dirc_img = pano_img[:, start_w:end_w]\n",
    "\n",
    "            # dirc_img = pano_img[:, x:x + ph]\n",
    "            # if x + ph > pw:\n",
    "            #     dirc_img = np.concatenate((dirc_img, pano_img[:, :x + ph - pw]), axis=1)\n",
    "            dirc_imgs.append(dirc_img)\n",
    "        return np.array(dirc_imgs)\n",
    "\n",
    "\n",
    "    def get_cand_node_dirc(self, pano_rgb, depth, pos, rot, vis_pos=None):\n",
    "        ## rot is rotation vector\n",
    "        cur_heading_idx = int(np.round(-rot[1] * 180 / np.pi / self.cand_rot_angle)) % self.rot_num\n",
    "        cand_nodes = []\n",
    "        cand_angle = [-30, 0, 30]\n",
    "        self.local_mapper.reset_map()\n",
    "        depth_cm = depth * 100\n",
    "        pose_origin_for_map = (pos[0], pos[2], 0)  # (x, y, o)\n",
    "        pose_for_map = (pos[0], pos[2], rot[1])  # (x, y, o)\n",
    "        pose_on_map_cm = self.local_mapper.get_mapper_pose_from_sim_pose(pose_for_map, pose_origin_for_map)\n",
    "        pose_on_map = self.local_mapper.get_map_grid_from_sim_pose_cm(pose_on_map_cm)\n",
    "\n",
    "        ### get current local map ###\n",
    "        curr_local_map, curr_exp_map, _ = self.local_mapper.update_map(depth_cm, pose_on_map_cm)\n",
    "        curr_local_map = (skimage.morphology.binary_dilation(\n",
    "            curr_local_map, skimage.morphology.disk(2)\n",
    "        )== True).astype(float)\n",
    "\n",
    "        # text = goal_info['category_place']\n",
    "        rot_axis = np.array([0, 1, 0])\n",
    "        # head = -quaternion.as_rotation_vector(rot)[1] * 180 / np.pi\n",
    "\n",
    "        # for global coordinate\n",
    "        # turn left = positive angle\n",
    "        # free cand angle idx --> right side is positive\n",
    "        free_cand_nodes = np.zeros(12)\n",
    "        angle_bias = np.where(self.cand_angle == -30)[0][0]\n",
    "\n",
    "        for i, angle in enumerate(cand_angle):\n",
    "            rot_vec = rot + np.radians(-angle) * rot_axis\n",
    "            unit_vec = -np.array([np.sin(rot_vec[1]), 0, np.cos(rot_vec[1])])\n",
    "            edge_cand_pos = pos + unit_vec * self.edge_range\n",
    "            cand_rot = rot_vec\n",
    "            cur_heading_idx = int(np.round(-rot_vec[1] * 180 / np.pi / self.cand_rot_angle)) % self.rot_num\n",
    "\n",
    "            short_cand_pos = pos + unit_vec * self.graph_map.min_node_dist\n",
    "            cand_poses = [edge_cand_pos, short_cand_pos]\n",
    "\n",
    "            for cp_idx, cand_pos in enumerate(cand_poses):\n",
    "                ## map coordinate for checking free space\n",
    "                cand_pose_for_map = (cand_pos[0], cand_pos[2], rot_vec[1])\n",
    "                cand_pose_on_grid_map_cm = self.local_mapper.get_mapper_pose_from_sim_pose(cand_pose_for_map, pose_origin_for_map)\n",
    "                cand_pose_on_grid_map = self.local_mapper.get_map_grid_from_sim_pose_cm(cand_pose_on_grid_map_cm)\n",
    "                if self.local_mapper.is_traversable(curr_local_map, pose_on_map, cand_pose_on_grid_map):\n",
    "                    cand_node_info = {'position': cand_pos, 'rotation': cand_rot, 'heading_idx': cur_heading_idx,\n",
    "                                      'pose_on_map': cand_pose_on_grid_map, 'cand_edge': []}\n",
    "\n",
    "                    # if self.vis_floorplan:\n",
    "                    vis_rot_vec = rot_vec + self.abs_init_rotation\n",
    "                    vis_unit_vec = -np.array([np.sin(vis_rot_vec[1]), 0, np.cos(vis_rot_vec[1])])\n",
    "                    if cp_idx == 0:\n",
    "                        vis_cand_pos = vis_pos + vis_unit_vec * self.edge_range\n",
    "                    else:\n",
    "                        vis_cand_pos = vis_pos + vis_unit_vec * self.graph_map.min_node_dist\n",
    "                    cand_node_info['vis_position'] = vis_cand_pos\n",
    "\n",
    "                    # for degbugging vis\n",
    "                    # vis_map = np.copy(curr_local_map)\n",
    "                    # vis_map[pose_on_map[0], pose_on_map[1]] = 2\n",
    "                    # vis_map[cand_pose_on_grid_map[0], cand_pose_on_grid_map[1]] = 2\n",
    "                    # plt.imsave('test_map.png',vis_map, origin='lower')\n",
    "\n",
    "                    # ## --- one step further node --- ##\n",
    "                    # next_pos = pos + unit_vec * self.edge_range * 2\n",
    "                    # next_pose_for_map = (next_pos[0], next_pos[2], rot_vec[1])\n",
    "                    # next_pose_on_grid_map_cm = self.local_mapper.get_mapper_pose_from_sim_pose(next_pose_for_map,\n",
    "                    #                                                                            pose_origin_for_map)\n",
    "                    # next_pose_on_grid_map = self.local_mapper.get_map_grid_from_sim_pose_cm(next_pose_on_grid_map_cm)\n",
    "                    # if self.local_mapper.is_traversable(curr_local_map, pose_on_map, next_pose_on_grid_map):\n",
    "                    #     cand_node_info['next_node'] = {'position': next_pos, 'rotation': cand_rot, 'heading_idx': cur_heading_idx}\n",
    "                    # else:\n",
    "                    cand_node_info['next_node'] = None\n",
    "\n",
    "                    cand_nodes.append(cand_node_info)\n",
    "                    free_cand_nodes[angle_bias + i] = 1\n",
    "\n",
    "                    break\n",
    "\n",
    "\n",
    "        # cand_nodes.append({'position': cand_pos, 'rotation': cand_rot})\n",
    "        #\n",
    "        pano_split_images = self.get_dirc_imgs_from_pano(pano_rgb)\n",
    "        cand_split_images = pano_split_images[np.where(free_cand_nodes == 1)[0]]\n",
    "\n",
    "        valid_cand_nodes = []\n",
    "        # similarity, cand_split_feat = self.common_sense_model.clip.get_text_image_sim(text, cand_split_images,\n",
    "        #                                                                               out_img_feat=True)\n",
    "        if len(cand_split_images) > 0:\n",
    "            cand_image_feat = self.common_sense_model.clip.get_image_feat(cand_split_images)\n",
    "            # cm_score, _ = self.common_sense_model.text_image_score(self.goal_place_text_feat, cand_image_feat, feat=True)\n",
    "            for i in range(len(cand_nodes)):\n",
    "                # if not self.graph_map.check_node_exist(cand_nodes[i]['position']):\n",
    "                    # value = np.round(np.max(similarity, axis=1), 3)\n",
    "                    # cand_nodes[i]['clip_feat'] = cand_split_feat[i]\n",
    "                    # cand_nodes[i]['value'] = value[i]\n",
    "\n",
    "                cand_nodes[i]['clip_feat'] = cand_image_feat[i]\n",
    "                for j in range(i + 1, len(cand_nodes)):\n",
    "                    if self.local_mapper.is_traversable(curr_local_map, cand_nodes[i]['pose_on_map'],\n",
    "                                                        cand_nodes[j]['pose_on_map']):\n",
    "                        cand_nodes[i]['cand_edge'].append(j)\n",
    "\n",
    "                # if cand_nodes[i]['next_node'] is not None:\n",
    "                #     cand_nodes[i]['next_node']['clip_feat'] = cand_image_feat[i]\n",
    "                # cand_nodes[i]['cm_score'] = cm_score[i]\n",
    "                valid_cand_nodes.append(cand_nodes[i])\n",
    "\n",
    "        return valid_cand_nodes\n",
    "\n",
    "    def check_cand_node_edge(self, cur_node, pano_rgb, pos, rot):\n",
    "        ## rot is rotation vector\n",
    "        cand_nodes = []\n",
    "        cand_angle = self.cand_angle\n",
    "        self.local_mapper.reset_map()\n",
    "        rot_axis = np.array([0, 1, 0])\n",
    "\n",
    "        # for global coordinate\n",
    "        # turn left = positive angle\n",
    "        # free cand angle idx --> right side is positive\n",
    "        torch.set_num_threads(1)\n",
    "        free_cand_nodes = self.free_space_model.predict_free_space(pano_rgb)\n",
    "        pano_split_images = self.get_dirc_imgs_from_pano(pano_rgb)\n",
    "\n",
    "        cand_node_edges = []\n",
    "\n",
    "        for i, angle in enumerate(cand_angle):\n",
    "            rot_vec = rot + np.radians(-angle) * rot_axis\n",
    "            unit_vec = -np.array([np.sin(rot_vec[1]), 0, np.cos(rot_vec[1])])\n",
    "            cand_pos = pos + unit_vec * self.edge_range\n",
    "            cur_heading_idx = int(np.round(-rot_vec[1] * 180 / np.pi / self.cand_rot_angle)) % self.rot_num\n",
    "\n",
    "            nearest_node_idx, nearest_node_dist = self.graph_map.get_nearest_node(cand_pos)\n",
    "            if nearest_node_dist < self.graph_map.max_edge_length and free_cand_nodes[\n",
    "                i] == 1 and not nearest_node_idx == cur_node.nodeid:\n",
    "                # cand_node = self.graph_map.node_by_id[nearest_node_idx]\n",
    "\n",
    "                cand_info = {\n",
    "                    'nearest_node_idx': nearest_node_idx,\n",
    "                    'nearest_node_dist': nearest_node_dist,\n",
    "                    'img': pano_split_images[i],\n",
    "                    'heading_idx': cur_heading_idx,\n",
    "                }\n",
    "                cand_node_edges.append(cand_info)\n",
    "\n",
    "        ## delete duplicate nearest node ###\n",
    "\n",
    "        connected_nodes = {}\n",
    "\n",
    "        for i in range(len(cand_node_edges)):\n",
    "            if cand_node_edges[i]['nearest_node_idx'] not in connected_nodes.keys():\n",
    "                connected_nodes[cand_node_edges[i]['nearest_node_idx']] = cand_node_edges[i]\n",
    "            elif connected_nodes[cand_node_edges[i]['nearest_node_idx']]['nearest_node_dist'] > cand_node_edges[i][\n",
    "                'nearest_node_dist']:\n",
    "                connected_nodes[cand_node_edges[i]['nearest_node_idx']] = cand_node_edges[i]\n",
    "\n",
    "        for key in connected_nodes.keys():\n",
    "            cand_node = self.graph_map.node_by_id[key]\n",
    "\n",
    "            # cand_image_feat = self.common_sense_model.clip.get_image_feat([pano_split_images[i]])\n",
    "            cand_image_feat = self.common_sense_model.clip.get_image_feat([connected_nodes[key]['img']])\n",
    "            self.graph_map.update_node_clip_feat(cand_node, cand_image_feat, connected_nodes[key]['heading_idx'])\n",
    "            self.graph_map.update_node_vis_feat(cand_node)\n",
    "\n",
    "            if self.cm_type == 'comet':\n",
    "                goal_cm_scores, _ = self.common_sense_model.text_image_score(self.goal_place_text_feat,\n",
    "                                                                             cand_image_feat, feat=True,\n",
    "                                                                             return_only_max=False)\n",
    "                # goal_cm_scores = torch.softmax(goal_cm_scores, dim=1)\n",
    "                goal_cm_scores = goal_cm_scores * 0.01\n",
    "                cand_node.update_goal_cm_scores(goal_cm_scores, connected_nodes[key]['heading_idx'])\n",
    "\n",
    "\n",
    "            elif self.cm_type == 'mp3d':\n",
    "                goal_cm_scores, _ = self.common_sense_model.text_image_score(self.cand_place_text_feat,\n",
    "                                                                             cand_image_feat, feat=True,\n",
    "                                                                             return_only_max=False)\n",
    "                goal_cm_scores = goal_cm_scores[:, :5]\n",
    "\n",
    "                goal_cm_scores = np.round(np.max(np.exp(goal_cm_scores) / np.sum(np.exp(goal_cm_scores)), axis=1), 5)\n",
    "                weighted_goal_cm_scores = goal_cm_scores * self.cand_category_room_score[self.goal_info['category']][\n",
    "                                                           :5]  ## weighted by room category\n",
    "                cand_node.update_goal_cm_scores(weighted_goal_cm_scores, connected_nodes[key]['heading_idx'])\n",
    "\n",
    "\n",
    "\n",
    "            self.graph_map.update_node_feat(cand_node)\n",
    "            self.graph_map.add_edge(cur_node, cand_node)\n",
    "\n",
    "        return\n",
    "\n",
    "    def get_value_graph(self):\n",
    "        nodes = [self.graph_map.node_by_id[id] for id in self.graph_map.node_by_id.keys()]\n",
    "        graph_size = len(nodes)\n",
    "\n",
    "        node_cm_scores = torch.zeros([graph_size, 12 * 10], dtype=torch.float)\n",
    "        node_features = torch.zeros([graph_size, 12 * self.args.vis_feat_dim], dtype=torch.float)\n",
    "        node_goal_features = torch.zeros([graph_size, self.args.vis_feat_dim], dtype=torch.float)\n",
    "        node_info_features = torch.zeros([graph_size, 1 + 3 + 12 * 10], dtype=torch.float)\n",
    "\n",
    "        # for i in range(graph_size):\n",
    "        #     node_cm_scores[i] = torch.Tensor([nodes[i].cm_score])\n",
    "        # softmax_node_cm_scores = torch.softmax(node_cm_scores, dim=0)\n",
    "\n",
    "        for i in range(graph_size):\n",
    "            node_features[i] = torch.reshape(nodes[i].clip_feat, [-1])\n",
    "            node_goal_features[i] = self.goal_category_feat[self.goal_class_idx]\n",
    "            node_cm_scores[i] = torch.reshape(nodes[i].goal_cm_scores, [-1])\n",
    "            node_info_features[i] = torch.cat([nodes[i].visited,\n",
    "                                               torch.Tensor(nodes[i].pos),\n",
    "                                               node_cm_scores[i]], dim=0)\n",
    "\n",
    "\n",
    "        ## -- compute edge weight -- ##\n",
    "        adj_mtx = torch.Tensor(self.graph_map.adj_mtx)\n",
    "        mask = adj_mtx > 0\n",
    "        adj_mtx[mask] = 1 / (1 + np.exp(-1 / adj_mtx[mask]))\n",
    "        adj_mtx = adj_mtx + torch.eye(graph_size)\n",
    "\n",
    "        node_features, node_goal_features, node_info_features, adj_mtx = \\\n",
    "            node_features.to(f'cuda:{self.args.model_gpu}'), \\\n",
    "            node_goal_features.to(f'cuda:{self.args.model_gpu}'), \\\n",
    "            node_info_features.to(f'cuda:{self.args.model_gpu}'), \\\n",
    "            adj_mtx.to(f'cuda:{self.args.model_gpu}')\n",
    "\n",
    "        object_value = self.value_model(node_features, node_goal_features, node_info_features, adj_mtx)\n",
    "        object_value = object_value.cpu().detach().numpy()\n",
    "\n",
    "        for i, node in enumerate(nodes):\n",
    "            node.pred_value = object_value[i]\n",
    "\n",
    "        del adj_mtx\n",
    "        return object_value\n",
    "\n",
    "\n",
    "\n",
    "    def get_next_subgoal_using_graph(self, cur_node, include_visited=False, except_node_id=None):\n",
    "        max_score = 0\n",
    "        min_dist = 9999\n",
    "        cand_node = None\n",
    "        max_dist = 30\n",
    "\n",
    "        ids = []\n",
    "        cm_scores = []\n",
    "        dist_scores = []\n",
    "        obj_scores = []\n",
    "        true_score = []\n",
    "        object_value = self.get_value_graph()\n",
    "\n",
    "        node_list = self.graph_map.candidate_node_ids\n",
    "        if include_visited:\n",
    "            node_list = node_list + self.graph_map.visited_node_ids\n",
    "        if except_node_id is not None:\n",
    "            for id in except_node_id:\n",
    "                if id in node_list:\n",
    "                    node_list.remove(id)\n",
    "\n",
    "        for i, id in enumerate(node_list):\n",
    "            node = self.graph_map.get_node_by_id(id)\n",
    "            ids.append(id)\n",
    "\n",
    "            cm_scores.append(node.cm_score)\n",
    "            obj_scores.append(np.squeeze(node.pred_value))\n",
    "\n",
    "            # dist score\n",
    "            temp_path, temp_path_length = self.get_shortest_path(cur_node.nodeid, id, self.graph_map.adj_mtx)\n",
    "            if len(temp_path) == 0:\n",
    "                dist_score = -9999\n",
    "            else:\n",
    "                # dist_score = max(1 - temp_path_length / max_dist, 0)\n",
    "                dist_score = 0\n",
    "            dist_scores.append(dist_score)\n",
    "\n",
    "\n",
    "            true_score.append(node.dist_to_objs[self.goal_class_idx])\n",
    "            # oracle score\n",
    "            if self.use_oracle:\n",
    "                if node.dist_to_objs[self.goal_class_idx] < min_dist:\n",
    "                    min_dist = node.dist_to_objs[self.goal_class_idx]\n",
    "                    cand_node = node\n",
    "\n",
    "\n",
    "\n",
    "        if self.use_oracle:\n",
    "            return cand_node, min_dist\n",
    "        else:\n",
    "            dist_scores = np.array(dist_scores)\n",
    "            # cm_scores = np.array(cm_scores)\n",
    "            # softmax_cm_scores = np.exp(cm_scores) / np.sum(np.exp(cm_scores))\n",
    "            # combined_score = 0.5 * softmax_cm_scores + 0.5 * dist_scores\n",
    "\n",
    "            obj_scores = np.array(obj_scores)\n",
    "            combined_score = obj_scores + dist_scores\n",
    "            # combined_score = obj_scores\n",
    "            node_idx = np.argmax(combined_score)\n",
    "            cand_node = self.graph_map.get_node_by_id(ids[node_idx])\n",
    "\n",
    "            return cand_node, combined_score[node_idx]\n",
    "\n",
    "\n",
    "    def check_close_goal_det(self, rgb, depth, vis=False):\n",
    "        if self.goal_cat == 'mp3d':\n",
    "            obj_min_dist = 9999\n",
    "            obj_min_pixel = None\n",
    "            closest_obj_id = None\n",
    "            rgb = rgb[:,:,:3]\n",
    "            torch.set_num_threads(1)\n",
    "            if vis:\n",
    "                img, pred_classes, scores, pred_out, masks, boxes = self.detector.predicted_img(rgb, show=True)\n",
    "            else:\n",
    "                pred_classes, scores, pred_out, masks, boxes = self.detector.predicted_img(rgb)\n",
    "            for i, goal_idx in enumerate(pred_classes):\n",
    "                if goal_idx == self.goal_class_idx:\n",
    "                    # if np.min(depth[masks[i]]) < th:\n",
    "                    #     close = True\n",
    "                    #     break\n",
    "                    # temp_min_dist = np.min(depth[masks[i]])\n",
    "                    # temp_min_dist = np.min(depth[np.nonzero(depth*masks[i])])\n",
    "                    nonzero_pixel = depth[np.nonzero(depth * masks[i])]\n",
    "                    temp_med_dist = np.sort(nonzero_pixel)[int(len(nonzero_pixel) / 2)]\n",
    "\n",
    "                    if temp_med_dist < obj_min_dist:\n",
    "                        obj_min_dist = temp_med_dist\n",
    "                        obj_min_pixel = np.argwhere(depth * masks[i] == temp_med_dist)[0]\n",
    "                        closest_obj_id = i\n",
    "\n",
    "                        ## get position from pixel\n",
    "\n",
    "            det_out = {\n",
    "                'pred_classes': pred_classes,\n",
    "                'scores': scores,\n",
    "                'pred_out': pred_out,\n",
    "                'masks': masks,\n",
    "                'boxes': boxes,\n",
    "                'closest_obj_id': closest_obj_id,\n",
    "                'obj_min_dist': obj_min_dist,\n",
    "                'obj_min_pixel': obj_min_pixel\n",
    "            }\n",
    "            if vis:\n",
    "                det_out['det_img'] = img\n",
    "            return det_out, obj_min_dist\n",
    "\n",
    "        elif self.goal_cat == 'mp3d_21':\n",
    "            rgb = rgb[:, :, :3]\n",
    "\n",
    "            in_rgb = np.transpose(rgb, (2, 0, 1))\n",
    "            in_depth = np.expand_dims(depth, axis=0)\n",
    "\n",
    "            in_rgb, in_depth = torch.from_numpy(in_rgb).float().to(f\"cuda:{self.args.model_gpu}\"), torch.from_numpy(in_depth).float().to(f\"cuda:{self.args.model_gpu}\")\n",
    "            in_rgb, in_depth = in_rgb.unsqueeze(0), in_depth.unsqueeze(0)\n",
    "            torch.set_num_threads(1)\n",
    "            pred = self.detector.get_predictions(in_rgb, in_depth)[0]\n",
    "\n",
    "            pred_mask = pred[self.goal_class_idx].cpu().numpy().astype(np.uint8)\n",
    "            depth_mask = (depth < self.last_mile_range).astype(np.uint8)\n",
    "            mask = pred_mask * depth_mask\n",
    "            nonzero_pixel = depth[np.nonzero(depth * mask)]\n",
    "\n",
    "            if len(nonzero_pixel) > 0:\n",
    "                temp_med_dist = np.sort(nonzero_pixel)[int(len(nonzero_pixel) / 2)]\n",
    "                obj_min_dist = temp_med_dist\n",
    "                obj_min_pixel = np.argwhere(depth * mask == temp_med_dist)[0]\n",
    "            else:\n",
    "                obj_min_dist = 9999\n",
    "                obj_min_pixel = None\n",
    "\n",
    "\n",
    "            det_out = {\n",
    "                'obj_min_dist': obj_min_dist,\n",
    "                'obj_min_pixel': obj_min_pixel\n",
    "            }\n",
    "            if vis:\n",
    "                det_img = self.detector.visualize_rednet_pred(pred)\n",
    "                alpha = 0.3\n",
    "                mask = np.repeat(np.sum(det_img, axis=2).astype(bool)[:, :, np.newaxis], 3, axis=2)\n",
    "                rgb[mask] = cv2.addWeighted(rgb, alpha, det_img, 1 - alpha, 0)[mask]\n",
    "\n",
    "                det_out['det_img'] = rgb\n",
    "            return det_out, obj_min_dist\n",
    "    \n",
    "    \n",
    "    def check_pano_goal_det(self, pano_rgb, curr_node, pos, rot, vis=False):\n",
    "#         pano_rgb = pano_rgb.astype(np.uint8)\n",
    "#         rot_axis = np.array([0, 1, 0])\n",
    "\n",
    "#         if vis:\n",
    "#             img, pred_classes, scores, pred_out, masks, boxes = self.detector.predicted_img(pano_rgb, show=True)\n",
    "#         else:\n",
    "#             pred_classes, scores, pred_out, masks, boxes = self.detector.predicted_img(pano_rgb)\n",
    "#         for i, goal_idx in enumerate(pred_classes):\n",
    "#             if goal_idx == self.goal_class_idx:\n",
    "#                 ## --- get heading of the object from the current rotation --- ##\n",
    "#                 center_x = int(np.median(np.where(np.sum(masks[i], axis=0) > 0)))\n",
    "#                 head_x = int(center_x / (np.shape(pano_rgb)[1]+1) * 12) - 1\n",
    "#                 rot_angle = self.cand_angle[head_x]\n",
    "\n",
    "\n",
    "#                 rot_to_face = rot_angle // self.act_rot\n",
    "#                 if rot_to_face < -180 / self.act_rot:\n",
    "#                     rot_to_face += int(360 / self.act_rot)\n",
    "#                 elif rot_to_face > 180 / self.act_rot:\n",
    "#                     rot_to_face -= int(360 / self.act_rot)\n",
    "#                 for rot in range(abs(rot_to_face)):\n",
    "#                     if rot_to_face < 0:\n",
    "#                         action = 'turn_left'\n",
    "#                     else:\n",
    "#                         action = 'turn_right'\n",
    "#                     self.end_episode = self.do_explicit_action(self.cur_node, action)\n",
    "#                     if self.end_episode:\n",
    "#                         # last mile navigation activated in explicit action\n",
    "#                         return\n",
    "\n",
    "        return\n",
    "\n",
    "    def get_position_from_pixel(self, cur_position, cur_rotation, depth, pixel):\n",
    "\n",
    "\n",
    "        width, height = np.shape(depth)[1], np.shape(depth)[0]\n",
    "        aspect_ratio = float(width) / float(height)\n",
    "        fov = np.deg2rad(self.vo_hfov)\n",
    "        f = width / 2.0 / np.tan(fov / 2.0)\n",
    "        # fy = fx / aspect_ratio\n",
    "        cy, cx = width / 2.0, height / 2.0\n",
    "\n",
    "        z = depth[pixel[0], pixel[1]]\n",
    "        x = (pixel[0] - cx) * z / f   # pixel height, pixel value up --> vis down\n",
    "        y = (pixel[1] - cy) * z / f   # pixel width, pixel value up --> vis right\n",
    "\n",
    "        rel_position = (y, x, -z)\n",
    "        rot = R.from_rotvec(cur_rotation)\n",
    "        rot.as_matrix()\n",
    "        target_position = cur_position + rot.apply(rel_position)\n",
    "\n",
    "        return target_position\n",
    "\n",
    "\n",
    "    def update_cand_node_to_graph(self, cur_node, cand_nodes, min_node_dist=None):\n",
    "        if len(cand_nodes) == 0:\n",
    "            return\n",
    "        cand_node_list = []\n",
    "        for cand_node_info in cand_nodes:\n",
    "            cand_node, add_new_node = self.graph_map.add_single_node(cand_node_info['position'], min_node_dist=min_node_dist)\n",
    "            # cand_node = self.graph_map.get_node_by_pos(cand_node_info['position'])\n",
    "            # if int(cand_node.nodeid) == len(self.graph_map.nodes)-1: ## new node\n",
    "            self.graph_map.update_node_goal_category(cand_node, self.goal_class_onehot)\n",
    "            self.graph_map.update_node_clip_feat(cand_node, cand_node_info['clip_feat'], cand_node_info['heading_idx'])\n",
    "            self.graph_map.update_node_vis_feat(cand_node)\n",
    "\n",
    "\n",
    "            torch.set_num_threads(1)\n",
    "            if self.cm_type == 'comet':\n",
    "                goal_cm_scores, _ = self.common_sense_model.text_image_score(self.goal_place_text_feat,\n",
    "                                                                             cand_node_info['clip_feat'], feat=True,\n",
    "                                                                             return_only_max=False)\n",
    "                # goal_cm_scores = torch.softmax(goal_cm_scores, dim=1)\n",
    "                goal_cm_scores = goal_cm_scores * 0.01\n",
    "                cand_node.update_goal_cm_scores(goal_cm_scores, cand_node_info['heading_idx'])\n",
    "\n",
    "\n",
    "            elif self.cm_type == 'mp3d':\n",
    "                goal_cm_scores, _ = self.common_sense_model.text_image_score(self.cand_place_text_feat,\n",
    "                                                                             cand_node_info['clip_feat'], feat=True,\n",
    "                                                                             return_only_max=False)\n",
    "                goal_cm_scores = goal_cm_scores[:, :5]\n",
    "\n",
    "                goal_cm_scores = np.round(np.max(np.exp(goal_cm_scores) / np.sum(np.exp(goal_cm_scores)), axis=1), 5)\n",
    "                weighted_goal_cm_scores = goal_cm_scores * self.cand_category_room_score[self.goal_info['category']][\n",
    "                                                           :5]  ## weighted by room category\n",
    "                cand_node.update_goal_cm_scores(weighted_goal_cm_scores, cand_node_info['heading_idx'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            self.graph_map.update_node_feat(cand_node)\n",
    "            if add_new_node:\n",
    "                # self.graph_map.update_node_cm_score(cand_node, cand_node_info['cm_score'])\n",
    "\n",
    "#                 curr_dist_to_objs, curr_is_valid = self.dist_to_objs(cand_node_info['position'] + self.abs_init_position)\n",
    "#                 self.graph_map.update_node_dist_to_objs(cand_node, curr_dist_to_objs)\n",
    "                # if self.vis_floorplan:\n",
    "                cand_node.vis_pos = cand_node_info['vis_position']\n",
    "\n",
    "            self.graph_map.add_edge(cur_node, cand_node)\n",
    "            cand_node_list.append(cand_node)\n",
    "            # elif np.linalg.norm(np.asarray(cur_node.pos) - np.asarray(cand_node.pos)) < self.edge_range * 1.05:\n",
    "            #     self.graph_map.add_edge(cur_node, cand_node)\n",
    "\n",
    "        for i, node in enumerate(cand_node_list):\n",
    "            for j in cand_nodes[i]['cand_edge']:\n",
    "                self.graph_map.add_edge(node, cand_node_list[j])\n",
    "\n",
    "\n",
    "\n",
    "    def get_shortest_path(self, start_node_id, end_node_id, adj_mtx):\n",
    "        start_node_id, end_node_id = int(start_node_id), int(end_node_id)\n",
    "\n",
    "        graph = csr_matrix(adj_mtx)\n",
    "        dist_matrix, predecessors = shortest_path(csgraph=graph, directed=False, return_predecessors=True)\n",
    "        path = [end_node_id]\n",
    "        while path[-1] != start_node_id:\n",
    "            path.append(predecessors[start_node_id, path[-1]])\n",
    "            if path[-1] == -9999:\n",
    "                return [], []\n",
    "        path.reverse()\n",
    "\n",
    "        path = [str(i) for i in path]\n",
    "        path_length = 0\n",
    "        for i, nodeid in enumerate(path[:-1]):\n",
    "            path_length += self.graph_map.adj_mtx[int(nodeid)][int(path[i + 1])]\n",
    "\n",
    "        return path[1:], path_length\n",
    "    \n",
    "    def init_runner(self):\n",
    "        \n",
    "        self.goal_category_room, self.goal_category_room_feat, self.goal_category_room_score, \\\n",
    "        self.cand_category_room, self.cand_category_room_feat, self.cand_category_room_score = \\\n",
    "            self.init_commonsense_candidate_room(self.goal_obj_names, mp3d_room_names)\n",
    "\n",
    "        self.goal_category_feat = self.common_sense_model.clip.get_text_feat(self.goal_obj_names).type(torch.float32)\n",
    "\n",
    "        env_start_time = time.time()\n",
    "        src_start_time = time.time()\n",
    "\n",
    "        data_idx = 0\n",
    "        self.cur_data_idx = data_idx\n",
    "        self.action_step = 0\n",
    "        self.goal_obs_consistency = {\n",
    "            'position': [],\n",
    "            'count': []\n",
    "        }\n",
    "        self.path_length = 1e-5\n",
    "        self.visited_positions = []\n",
    "\n",
    "        \n",
    "        self.abs_init_position = np.zeros([3])\n",
    "        self.abs_init_rotation = np.zeros([3])\n",
    "        self.abs_init_heading = -self.abs_init_rotation[1] * 180 / np.pi\n",
    "\n",
    "        self.abs_position = np.zeros([3])\n",
    "        self.abs_rotation = np.zeros([3])\n",
    "\n",
    "        self.cur_position = np.zeros([3])\n",
    "        self.cur_rotation = np.zeros([3])\n",
    "        self.cur_heading = np.zeros([3])\n",
    "\n",
    "        ## -- floor plan -- ##\n",
    "        if self.vis_floorplan:\n",
    "            self.base_map = np.ones([1000,1000,3]).astype(np.uint8)*255\n",
    "            self.cur_graph_map = np.zeros_like(self.base_map).astype(np.uint8)\n",
    "        \n",
    "        self.end_episode = False\n",
    "        self.object_goal_position = None\n",
    "        self.vis_object_goal_position = None\n",
    "        \n",
    "#         obs = self._sim.get_sensor_observations()\n",
    "        get_robot_obs = False\n",
    "        while not get_robot_obs:\n",
    "            try:\n",
    "                obs = controller.get_obs()\n",
    "                get_robot_obs = True\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"KeyboardInterrupt\")\n",
    "                break\n",
    "            except:\n",
    "                print('Connection error occured')\n",
    "                pass\n",
    "        \n",
    "        self.goal_name = self.goal_obj_names[self.goal_class_idx]\n",
    "        self.goal_class_onehot = torch.zeros([len(self.goal_obj_names)])\n",
    "        self.goal_class_onehot[self.goal_class_idx] = 1\n",
    "        \n",
    "        self.goal_info = {}\n",
    "        \n",
    "        self.goal_info['category'] = self.goal_name\n",
    "        self.goal_info['category_place'] = self.goal_category_room[self.goal_name]\n",
    "        self.goal_info['category_place_score'] = self.goal_category_room_score[self.goal_name]\n",
    "        self.goal_place_text_feat = self.goal_category_room_feat[self.goal_name]\n",
    "\n",
    "        if self.vis_floorplan:\n",
    "            self.vis_traj = []\n",
    "            self.vis_info = {\n",
    "                'target_goal': self.goal_obj_names[self.goal_class_idx],\n",
    "                'mode': 'Exploration',\n",
    "                'cur_position': self.cur_position,\n",
    "                'obj_position': None,\n",
    "                'step': 0\n",
    "            }\n",
    "        \n",
    "        self.graph_map = GraphMap(self.args)\n",
    "        self.graph_map.goal_text_clip_feat = self.goal_category_feat[self.goal_class_idx]\n",
    "        self.graph_map.goal_cm_info = {\n",
    "                'goal_category_room': self.goal_category_room[self.goal_info['category']],\n",
    "                'goal_category_room_feat': self.goal_category_room_feat[self.goal_info['category']],\n",
    "                'goal_category_room_score': self.goal_category_room_score[self.goal_info['category']],\n",
    "                'cand_category_room': self.cand_category_room[self.goal_info['category']],\n",
    "                'cand_category_room_feat': self.cand_category_room_feat[self.goal_info['category']],\n",
    "                'cand_category_room_score': self.cand_category_room_score[self.goal_info['category']],\n",
    "            }\n",
    "\n",
    "#         pano_obs = self.panoramic_obs(obs, semantic=True)\n",
    "        self.pano_rgb_list = [obs['rgb_panoramic']]\n",
    "        self.rgb_list = [obs['color_sensor']]\n",
    "        self.depth_list = [obs['depth_sensor']]\n",
    "        det, det_dist = self.check_close_goal_det(obs['color_sensor'], obs['depth_sensor'], vis=True)\n",
    "\n",
    "\n",
    "        self.cur_node, _ = self.graph_map.add_single_node(self.cur_position)\n",
    "        if self.vis_floorplan:\n",
    "            self.cur_node.vis_pos = self.cur_position\n",
    "\n",
    "        self.graph_map.update_node_goal_category(self.cur_node, self.goal_class_onehot)\n",
    "        pano_images = self.get_dirc_imgs_from_pano(self.pano_rgb_list[-1])\n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "        pano_images_feat = self.common_sense_model.clip.get_image_feat(pano_images).type(torch.float32).detach().cpu()\n",
    "        cur_heading_idx = int(np.round(-self.cur_rotation[1] * 180 / np.pi / self.cand_rot_angle)) % self.rot_num\n",
    "\n",
    "        for i in range(len(pano_images)):\n",
    "            dirc_head_idx = (cur_heading_idx - 5 + i) % self.rot_num\n",
    "            self.graph_map.update_node_clip_feat(self.cur_node, pano_images_feat[i], dirc_head_idx)\n",
    "\n",
    "            if self.cm_type == 'comet':\n",
    "                goal_cm_scores, _ = self.common_sense_model.text_image_score(self.goal_place_text_feat,\n",
    "                                                                             pano_images_feat[i], feat=True,\n",
    "                                                                             return_only_max=False)\n",
    "                # goal_cm_scores = torch.softmax(goal_cm_scores, dim=1)\n",
    "                goal_cm_scores = goal_cm_scores * 0.01\n",
    "                self.cur_node.update_goal_cm_scores(goal_cm_scores, dirc_head_idx)\n",
    "\n",
    "\n",
    "            elif self.cm_type == 'mp3d':\n",
    "                goal_cm_scores, _ = self.common_sense_model.text_image_score(self.cand_place_text_feat,\n",
    "                                                                             pano_images_feat[i], feat=True,\n",
    "                                                                             return_only_max=False)\n",
    "                goal_cm_scores = goal_cm_scores[:, :5]\n",
    "\n",
    "                goal_cm_scores = np.round(np.max(np.exp(goal_cm_scores) / np.sum(np.exp(goal_cm_scores)), axis=1), 5)\n",
    "                weighted_goal_cm_scores = goal_cm_scores * self.cand_category_room_score[self.goal_info['category']][:5]  ## weighted by room category\n",
    "                self.cur_node.update_goal_cm_scores(weighted_goal_cm_scores, dirc_head_idx)\n",
    "        self.graph_map.update_node_vis_feat(self.cur_node)\n",
    "\n",
    "#         cm_scores, _ = self.common_sense_model.text_image_score(self.goal_place_text_feat,\n",
    "#                                                                 self.cur_node.vis_feat, feat=True,\n",
    "#                                                                 return_only_max=False)\n",
    "#         cm_score = np.round(np.max(np.exp(cm_scores) / np.sum(np.exp(cm_scores)), axis=1), 5)\n",
    "#         arg_cm_score = np.argmax(cm_scores, axis=1)\n",
    "\n",
    "#         cm_info = {\n",
    "#             'goal_place_name': self.goal_info['category_place'],\n",
    "#             'goal_place_feat': self.goal_place_text_feat,\n",
    "#             'goal_place_score': cm_scores,\n",
    "#         }\n",
    "#         self.graph_map.update_node_cm_score(self.cur_node,\n",
    "#                                             cm_score[0] * self.goal_info['category_place_score'][arg_cm_score[0]]\n",
    "#                                             , cm_name=self.goal_info['category_place'][arg_cm_score[0]]\n",
    "#                                             , cm_info=cm_info)\n",
    "\n",
    "        self.graph_map.update_node_visited(self.cur_node)\n",
    "        self.graph_map.update_node_feat(self.cur_node)\n",
    "        self.graph_map.update_node_is_start(self.cur_node)\n",
    "\n",
    "\n",
    "        ## update candidate node\n",
    "\n",
    "        cand_nodes = self.get_cand_node_dirc(self.pano_rgb_list[-1], self.depth_list[-1], self.cur_position, self.cur_rotation, self.cur_node.vis_pos)\n",
    "        self.update_cand_node_to_graph(self.cur_node, cand_nodes)\n",
    "\n",
    "        if self.vis_floorplan:\n",
    "            vis_graph_map = self.vis_topdown_map_with_captions(self.graph_map,\n",
    "                                                               curr_node=self.cur_node,\n",
    "                                                               bias_position=self.abs_init_position,\n",
    "                                                               # vis_goal_obj_score=self.goal_class_idx,\n",
    "                                                               )\n",
    "            vis_local_map = np.zeros([241, 241, 3])\n",
    "            self.vis_info['cur_position'] = self.cur_position\n",
    "            self.vis_info['mode'] = 'Exploration'\n",
    "            \n",
    "            det_pano, _, _, _, _, _ = self.detector.predicted_img(self.pano_rgb_list[-1], show=True)\n",
    "            total_frame = self.make_total_frame(det['det_img'], obs['depth_sensor'], \n",
    "                                                vis_graph_map, vis_local_map, \n",
    "                                                pano_rgb=det_pano,\n",
    "                                                info=self.vis_info,\n",
    "                                                frame_num=len(self.vis_traj))\n",
    "            self.vis_traj.append(total_frame)\n",
    "\n",
    "        \n",
    "        print(\"Initialize runner\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def last_mile_navigation(self, last_mile_obs):\n",
    "        curr_position = self.cur_position\n",
    "        curr_rotation = self.cur_rotation\n",
    "        last_mile_start_position = self.cur_position\n",
    "        last_mile_start_rotation = self.cur_rotation\n",
    "\n",
    "        ## get target position from the consistency\n",
    "        goal_obs_idx = np.argmax(self.goal_obs_consistency['count'])\n",
    "        goal_obs_position = self.goal_obs_consistency['position'][goal_obs_idx]\n",
    "        goal_obs_count = self.goal_obs_consistency['count'][goal_obs_idx]\n",
    "\n",
    "        target_position = self.goal_obs_consistency['position'][np.argmax(self.goal_obs_consistency['count'])]\n",
    "        self.object_goal_position = np.copy(target_position)\n",
    "        self.vis_object_goal_position = np.copy(self.goal_obs_consistency['vis_position'][np.argmax(self.goal_obs_consistency['count'])])\n",
    "\n",
    "        self.local_agent.reset_with_curr_pose(curr_position, curr_rotation)\n",
    "        delta_dist, delta_rot = get_relative_location(curr_position, curr_rotation, target_position)\n",
    "        self.local_agent.update_gt_local_map(last_mile_obs['depth_sensor'])\n",
    "        self.local_agent.set_goal(delta_dist, delta_rot)\n",
    "\n",
    "        object_goal_loc = np.copy(self.local_agent.goal)\n",
    "        # get nearest navigable goal\n",
    "        self.local_agent.goal, goal_updated = self.local_agent.get_neareset_navigable_goal(\n",
    "            self.local_agent.gt_local_map,\n",
    "            (self.local_agent.stg_x, self.local_agent.stg_y),\n",
    "            object_goal_loc)\n",
    "        if goal_updated:\n",
    "            target_position = self.local_mapper.get_sim_pose_from_mapper_coords(self.local_agent.goal,\n",
    "                                                                                last_mile_start_position,\n",
    "                                                                                last_mile_start_rotation)\n",
    "        if self.vis_floorplan:\n",
    "            self.visited_positions.append(curr_position)\n",
    "            \n",
    "            \n",
    "#         obs = self._sim.get_sensor_observations()\n",
    "        get_robot_obs = False\n",
    "        while not get_robot_obs:\n",
    "            try:\n",
    "                obs = controller.get_obs()\n",
    "                get_robot_obs = True\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"KeyboardInterrupt\")\n",
    "                break\n",
    "            except:\n",
    "                print('Connection error occured')\n",
    "                pass\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        while True:\n",
    "            if self.dist_euclidean_floor(curr_position, target_position) < self.step_size or \\\n",
    "                    self.dist_euclidean_floor(curr_position, self.object_goal_position) < 1.0 - (\n",
    "                    self.step_size / 2 + 0.05):\n",
    "                break\n",
    "\n",
    "            prev_obs = obs\n",
    "            prev_rgb = obs['color_sensor'][:, :, :3]\n",
    "            prev_depth = obs['depth_sensor']\n",
    "            prev_local_map = self.local_agent.gt_local_map\n",
    "\n",
    "            action, terminate_local = self.local_agent.navigate_local(gt=True)\n",
    "            action = self.local_agent.action_idx_map[action]\n",
    "            prev_position = curr_position\n",
    "            \n",
    "            \n",
    "#             obs = self._sim.step(action)\n",
    "#             obs = controller.pub_cmd(action)\n",
    "            get_robot_obs = False\n",
    "            while not get_robot_obs:\n",
    "                try:\n",
    "                    obs = controller.pub_cmd(action)\n",
    "                    get_robot_obs = True\n",
    "                except KeyboardInterrupt:\n",
    "                    print(\"KeyboardInterrupt\")\n",
    "                    break\n",
    "                except:\n",
    "                    print('Connection error occured')\n",
    "                    pass\n",
    "    \n",
    "    \n",
    "            \n",
    "            curr_agent_view, curr_local_map, _, _ = self.local_agent.mapper.get_curr_obsmap(obs['depth_sensor'] * 100.)\n",
    "            curr_rgb = obs['color_sensor'][:, :, :3]\n",
    "            for _ in range(5):\n",
    "                est_pos_diff, est_rot_diff, vo_success = self.get_vo_relative_camera_pose(prev_rgb, prev_depth,\n",
    "                                                                                          curr_rgb, action,\n",
    "                                                                                          self.cur_rotation,\n",
    "                                                                                          prev_local_map, curr_local_map)\n",
    "                if vo_success: break\n",
    "            curr_position = self.cur_position + est_pos_diff\n",
    "            curr_rotation = self.cur_rotation + est_rot_diff\n",
    "            self.cur_position = curr_position\n",
    "            self.cur_rotation = curr_rotation\n",
    "            \n",
    "            self.path_length += self.dist_euclidean_floor(prev_position, curr_position)\n",
    "\n",
    "\n",
    "\n",
    "            det, det_dist = self.check_close_goal_det(obs['color_sensor'], obs['depth_sensor'], vis=True)\n",
    "\n",
    "            # self.rgb_list.append(det['det_img'])\n",
    "            self.rgb_list.append(obs['color_sensor'])\n",
    "            self.depth_list.append(obs['depth_sensor'])\n",
    "\n",
    "            \n",
    "#             if obs['collided'] or \\\n",
    "#                     (action == 'move_forward' and np.linalg.norm(est_pos_diff) < self.step_size * 0.3):\n",
    "            if action == 'move_forward' and np.linalg.norm(est_pos_diff) < self.step_size * 0.3:\n",
    "                self.local_agent.collision = True\n",
    "            self.action_step += 1\n",
    "\n",
    "            self.local_agent.gt_new_sim_origin = get_sim_location(curr_position,\n",
    "                                                                  quaternion.from_rotation_vector(curr_rotation))\n",
    "            self.local_agent.update_gt_local_map(obs['depth_sensor'])\n",
    "\n",
    "            if self.vis_floorplan:\n",
    "                self.visited_positions.append(curr_position)\n",
    "                vis_graph_map = self.vis_topdown_map_with_captions(self.graph_map,\n",
    "                                                                   curr_node=self.cur_node,\n",
    "                                                                   bias_position=self.abs_init_position,\n",
    "                                                                   curr_position=curr_position,\n",
    "                                                                   curr_goal_position=self.object_goal_position,\n",
    "                                                                   visited_positions=self.visited_positions)\n",
    "                vis_local_map = self.local_agent.get_observed_colored_map(gt=True)\n",
    "\n",
    "                self.vis_info['cur_position'] = curr_position\n",
    "                self.vis_info['mode'] = 'Last mile'\n",
    "#                 det_pano, _, _, _, _, _ = self.detector.predicted_img(self.pano_rgb_list[-1], show=True)\n",
    "                total_frame = self.make_total_frame(det['det_img'], obs['depth_sensor'], vis_graph_map, vis_local_map,\n",
    "                                                    pano_rgb=self.pano_rgb_list[-1],\n",
    "                                                    info=self.vis_info, frame_num=len(self.vis_traj))\n",
    "                self.vis_traj.append(total_frame)\n",
    "\n",
    "            if self.action_step > self.max_step:\n",
    "                return\n",
    "\n",
    "            if det_dist < self.last_mile_range:\n",
    "                obs_goal_position = self.get_position_from_pixel(curr_position, curr_rotation, obs['depth_sensor'],\n",
    "                                                                 det['obj_min_pixel'])\n",
    "                if np.linalg.norm(self.object_goal_position - obs_goal_position) < 1.0 - self.step_size:\n",
    "                    goal_obs_count += 1\n",
    "                    self.object_goal_position = (self.object_goal_position * (\n",
    "                                goal_obs_count - 1) + obs_goal_position) / goal_obs_count\n",
    "\n",
    "                    delta_dist, delta_rot = get_relative_location(curr_position, curr_rotation,\n",
    "                                                                  self.object_goal_position)\n",
    "\n",
    "\n",
    "\n",
    "                    self.local_agent.set_goal(delta_dist, delta_rot)\n",
    "                    object_goal_loc = np.copy(self.local_agent.goal)\n",
    "\n",
    "            self.local_agent.goal, goal_updated = self.local_agent.get_neareset_navigable_goal(\n",
    "                self.local_agent.gt_local_map,\n",
    "                (self.local_agent.stg_x, self.local_agent.stg_y),\n",
    "                object_goal_loc)\n",
    "            if goal_updated:\n",
    "                target_position = self.local_mapper.get_sim_pose_from_mapper_coords(self.local_agent.goal,\n",
    "                                                                                    last_mile_start_position,\n",
    "                                                                                    last_mile_start_rotation)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def do_explicit_action(self, cur_node, action, curr_goal_node=None):\n",
    "        \n",
    "#         prev_obs = self._sim.get_sensor_observations()\n",
    "#         prev_obs = controller.get_obs()\n",
    "        get_robot_obs = False\n",
    "        while not get_robot_obs:\n",
    "            try:\n",
    "                prev_obs = controller.get_obs()\n",
    "                get_robot_obs = True\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"KeyboardInterrupt\")\n",
    "                break\n",
    "            except:\n",
    "                print('Connection error occured')\n",
    "                pass\n",
    "        \n",
    "        \n",
    "        prev_rgb = prev_obs['color_sensor'][:,:,:3]\n",
    "        prev_depth = prev_obs['depth_sensor']\n",
    "        prev_position = self.cur_position\n",
    "        prev_local_map = self.local_agent.gt_local_map\n",
    "        \n",
    "        \n",
    "#         obs = self._sim.step(action)\n",
    "#         obs = controller.pub_cmd(action)\n",
    "        get_robot_obs = False\n",
    "        while not get_robot_obs:\n",
    "            try:\n",
    "                obs = controller.pub_cmd(action)\n",
    "                get_robot_obs = True\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"KeyboardInterrupt\")\n",
    "                break\n",
    "            except:\n",
    "                print('Connection error occured')\n",
    "                pass\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        curr_rgb = obs['color_sensor'][:,:,:3]\n",
    "        curr_agent_view, curr_local_map, _, _ = self.local_agent.mapper.get_curr_obsmap(obs['depth_sensor'] * 100.)\n",
    "\n",
    "        \n",
    "        for _ in range(5):\n",
    "            est_pos_diff, est_rot_diff, vo_success = self.get_vo_relative_camera_pose(prev_rgb, prev_depth, curr_rgb,\n",
    "                                                                                      action, self.cur_rotation, prev_local_map, curr_local_map)\n",
    "            if vo_success: break\n",
    "        curr_position = self.cur_position + est_pos_diff\n",
    "        curr_rotation = self.cur_rotation + est_rot_diff\n",
    "        print(f'Step {len(self.vis_traj)} Action {action} vo success:{vo_success}, pos diff:{est_pos_diff}, rot diff:{np.rad2deg(est_rot_diff[1])}')\n",
    "        print('                          pose {}'.format(obs['pose']))\n",
    "        self.cur_position = curr_position\n",
    "        self.cur_rotation = curr_rotation\n",
    "        \n",
    "        self.path_length += self.dist_euclidean_floor(prev_position, curr_position)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         pano_obs = self.panoramic_obs(obs, semantic=False)\n",
    "        self.pano_rgb_list.append(obs['rgb_panoramic'])\n",
    "        self.rgb_list.append(obs['color_sensor'])\n",
    "        self.depth_list.append(obs['depth_sensor'])\n",
    "\n",
    "        det, det_dist = self.check_close_goal_det(obs['color_sensor'], obs['depth_sensor'], vis=True)\n",
    "\n",
    "        if det_dist < self.last_mile_range:\n",
    "            obs_goal_position = self.get_position_from_pixel(curr_position, curr_rotation, obs['depth_sensor'],\n",
    "                                                             det['obj_min_pixel'])\n",
    "            curr_state = self._sim.agents[0].get_state()\n",
    "            vis_obs_goal_position = self.get_position_from_pixel(curr_state.position - self.abs_init_position,\n",
    "                                                                 quaternion.as_rotation_vector(curr_state.rotation), obs['depth_sensor'],\n",
    "                                                                 det['obj_min_pixel'])\n",
    "            new_goal_obj_det = True\n",
    "            for cand_goal_idx in range(len(self.goal_obs_consistency['position'])):\n",
    "                if np.linalg.norm(self.goal_obs_consistency['position'][cand_goal_idx] - obs_goal_position) < 1.0:\n",
    "                    self.goal_obs_consistency['count'][cand_goal_idx] += 1\n",
    "                    # self.goal_obs_consistency['position'][cand_goal_idx] = obs_goal_position\n",
    "                    self.goal_obs_consistency['position'][cand_goal_idx] = \\\n",
    "                        (self.goal_obs_consistency['position'][cand_goal_idx] * (\n",
    "                                    self.goal_obs_consistency['count'][cand_goal_idx] - 1) + obs_goal_position) / \\\n",
    "                        self.goal_obs_consistency['count'][cand_goal_idx]\n",
    "                    self.goal_obs_consistency['vis_position'][cand_goal_idx] = \\\n",
    "                        (self.goal_obs_consistency['vis_position'][cand_goal_idx] * (\n",
    "                                    self.goal_obs_consistency['count'][cand_goal_idx] - 1) + vis_obs_goal_position) / \\\n",
    "                        self.goal_obs_consistency['count'][cand_goal_idx]\n",
    "                    new_goal_obj_det = False\n",
    "                    break\n",
    "            if new_goal_obj_det:\n",
    "                self.goal_obs_consistency['position'].append(obs_goal_position)\n",
    "                self.goal_obs_consistency['vis_position'].append(vis_obs_goal_position)\n",
    "                self.goal_obs_consistency['count'].append(1)\n",
    "\n",
    "\n",
    "        if self.vis_floorplan:\n",
    "            self.visited_positions.append(curr_position)\n",
    "            vis_graph_map = self.vis_topdown_map_with_captions(self.graph_map,\n",
    "                                                               curr_node=self.cur_node,\n",
    "                                                               bias_position=np.array([0,0,0]),\n",
    "                                                               curr_position=curr_position,\n",
    "                                                               curr_goal_node=curr_goal_node,\n",
    "                                                               visited_positions=self.visited_positions)\n",
    "#             vis_local_map = np.zeros([241, 241, 3])\n",
    "#             self.local_agent.reset_with_curr_pose(curr_position, curr_rotation)\n",
    "#             delta_dist, delta_rot = get_relative_location(curr_position, curr_rotation, curr_position)\n",
    "            self.local_agent.gt_new_sim_origin = get_sim_location(curr_position, quaternion.from_rotation_vector(curr_rotation))\n",
    "            self.local_agent.update_gt_local_map(obs['depth_sensor'])\n",
    "#             self.local_agent.set_goal(delta_dist, delta_rot)\n",
    "            vis_local_map = self.local_agent.get_observed_colored_map(gt=True)\n",
    "                                                               # vis_goal_obj_score=self.goal_class_idx)\n",
    "            self.vis_info['cur_position'] = curr_position\n",
    "            self.vis_info['mode'] = 'node search'\n",
    "            self.vis_info['step'] = self.action_step\n",
    "#             det_pano, _, _, _, _, _ = self.detector.predicted_img(self.pano_rgb_list[-1], show=True)\n",
    "            total_frame = self.make_total_frame(det['det_img'], obs['depth_sensor'], \n",
    "                                                vis_graph_map, vis_local_map, \n",
    "                                                pano_rgb=self.pano_rgb_list[-1],\n",
    "                                                info=self.vis_info, frame_num=len(self.vis_traj))\n",
    "            self.vis_traj.append(total_frame)\n",
    "\n",
    "        self.action_step += 1\n",
    "\n",
    "        ## update candidate node\n",
    "        cand_nodes = self.get_cand_node_dirc(self.pano_rgb_list[-1],\n",
    "                                             self.depth_list[-1], curr_position, curr_rotation, vis_pos=cur_node.vis_pos)\n",
    "        self.update_cand_node_to_graph(cur_node, cand_nodes)\n",
    "        \n",
    "        self.check_pano_goal_det(obs['rgb_panoramic'], self.cur_node, curr_position, curr_rotation, vis=True)\n",
    "        if self.end_episode:\n",
    "            return self.end_episode\n",
    "        \n",
    "        if not action == 'move_forward':\n",
    "            ### -- update current position -- ###\n",
    "            self.cur_position = np.array(cur_node.pos)\n",
    "\n",
    "        self.end_episode = False\n",
    "\n",
    "        self.end_episode = False\n",
    "        if len(self.goal_obs_consistency['count']) > 0:\n",
    "            if np.max(self.goal_obs_consistency['count']) >= self.goal_obs_consistency_th:\n",
    "                self.last_mile_navigation(obs)\n",
    "                self.end_episode = True\n",
    "                return self.end_episode\n",
    "\n",
    "        return self.end_episode\n",
    "\n",
    "    def do_panoramic_action(self, cur_node):\n",
    "        self.local_agent.reset_with_curr_pose(self.cur_position, self.cur_rotation)\n",
    "        \n",
    "        get_robot_obs = False\n",
    "        while not get_robot_obs:\n",
    "            try:\n",
    "                obs = controller.pub_cmd(action)\n",
    "                get_robot_obs = True\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"KeyboardInterrupt\")\n",
    "                break\n",
    "            except:\n",
    "                print('Connection error occured')\n",
    "                pass\n",
    "\n",
    "        \n",
    "        delta_dist, delta_rot = get_relative_location(self.cur_position, self.cur_rotation, self.cur_position)\n",
    "        self.local_agent.update_gt_local_map(obs['depth_sensor'])\n",
    "        self.local_agent.set_goal(delta_dist, delta_rot)\n",
    "        \n",
    "        \n",
    "        action = 'turn_left'\n",
    "        for i in range(int(360/self.act_rot)):\n",
    "            self.end_episode = self.do_explicit_action(cur_node, action)\n",
    "            if self.end_episode:\n",
    "                break\n",
    "        return\n",
    "\n",
    "    def do_time_steps(self):\n",
    "\n",
    "        curr_position = self.cur_position\n",
    "        curr_rotation = self.cur_rotation\n",
    "\n",
    "\n",
    "        max_action_step = False\n",
    "        last_mile_navi_mode = False\n",
    "        last_mile_obs = None\n",
    "        last_mile_det = None\n",
    "        invalid_edge = False\n",
    "        invalid_edge_node = []\n",
    "\n",
    "\n",
    "        arrive_node = False\n",
    "        find_frontier = False\n",
    "        find_frontier_visited_node_id = []\n",
    "\n",
    "        while True:\n",
    "            if self.end_episode:\n",
    "                return\n",
    "#             if len(self.graph_map.candidate_node_ids) <= 2:\n",
    "#                 self.do_panoramic_action(self.cur_node)\n",
    "            if len(self.graph_map.candidate_node_ids) == 0 or find_frontier:\n",
    "                self.do_panoramic_action(self.cur_node)\n",
    "\n",
    "            if invalid_edge:\n",
    "                # return to the previous node\n",
    "                # temp_goal_node = self.graph_map.get_node_by_id(self.cur_node.nodeid)\n",
    "                # temp_goal_position = self.cur_node.pos\n",
    "                cur_node_id, _ = self.graph_map.get_nearest_node(curr_position, except_node_id=invalid_edge_node)\n",
    "                temp_goal_node = self.graph_map.get_node_by_id(cur_node_id)\n",
    "                temp_goal_position = temp_goal_node.pos\n",
    "            else:\n",
    "                if len(self.graph_map.candidate_node_ids) > 0:\n",
    "                    subgoal_node, object_value = self.get_next_subgoal_using_graph(self.cur_node)\n",
    "                    if object_value < 0:\n",
    "                        find_frontier_visited_node_id.append(self.cur_node.nodeid)\n",
    "                        find_frontier = True\n",
    "                        subgoal_node, object_value = self.get_next_subgoal_using_graph(self.cur_node,\n",
    "                                                                                       include_visited=True,\n",
    "                                                                                       except_node_id=find_frontier_visited_node_id)\n",
    "                    else:\n",
    "                        find_frontier = False\n",
    "                        find_frontier_visited_node_id = []\n",
    "                else:\n",
    "                    find_frontier_visited_node_id.append(self.cur_node.nodeid)\n",
    "                    find_frontier = True\n",
    "                    subgoal_node, object_value = self.get_next_subgoal_using_graph(self.cur_node, include_visited=True,\n",
    "                                                                                   except_node_id=find_frontier_visited_node_id)\n",
    "\n",
    "                # if subgoal_node == None:\n",
    "                #     return\n",
    "\n",
    "                subgoal_id = subgoal_node.nodeid\n",
    "\n",
    "                temp_path, _ = self.get_shortest_path(self.cur_node.nodeid, subgoal_id, self.graph_map.adj_mtx)\n",
    "\n",
    "                # for node_id in temp_path:\n",
    "                ## --- one node step update --- ##\n",
    "                if len(temp_path) == 0:\n",
    "                    return\n",
    "                node_id = temp_path[0]\n",
    "                temp_goal_node = self.graph_map.get_node_by_id(node_id)\n",
    "                temp_goal_position = temp_goal_node.pos\n",
    "\n",
    "            \n",
    "            \n",
    "#             obs = self._sim.get_sensor_observations()\n",
    "            get_robot_obs = False\n",
    "            while not get_robot_obs:\n",
    "                try:\n",
    "                    obs = controller.get_obs()\n",
    "                    get_robot_obs = True\n",
    "                except KeyboardInterrupt:\n",
    "                    print(\"KeyboardInterrupt\")\n",
    "                    break\n",
    "                except:\n",
    "                    print('Connection error occured')\n",
    "                    pass\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if len(self.goal_obs_consistency['count']) > 0:\n",
    "                if np.max(self.goal_obs_consistency['count']) >= self.goal_obs_consistency_th:\n",
    "                    self.last_mile_navigation(obs)\n",
    "                    return\n",
    "\n",
    "\n",
    "            self.local_agent.reset_with_curr_pose(curr_position, curr_rotation)\n",
    "            delta_dist, delta_rot = get_relative_location(curr_position, curr_rotation, temp_goal_position)\n",
    "            self.local_agent.update_gt_local_map(obs['depth_sensor'])\n",
    "            self.local_agent.set_goal(delta_dist, delta_rot)\n",
    "            curr_agent_view, curr_local_map, _, _ = self.local_agent.mapper.get_curr_obsmap(obs['depth_sensor'] * 100.)\n",
    "\n",
    "            if self.vis_floorplan:\n",
    "                self.visited_positions.append(curr_position)\n",
    "                vis_graph_map = self.vis_topdown_map_with_captions(self.graph_map,\n",
    "                                                                   curr_node=self.cur_node,\n",
    "                                                                   bias_position=self.abs_init_position,\n",
    "                                                                   curr_position=curr_position,\n",
    "                                                                   curr_goal_node=subgoal_node,\n",
    "                                                                   visited_positions=self.visited_positions)\n",
    "#                 vis_local_map = self.local_agent.get_observed_colored_map(gt=True)\n",
    "                                                                   # vis_goal_obj_score=self.goal_class_idx)\n",
    "            local_action_cnt = 0\n",
    "            terminate_local = False\n",
    "            while self.dist_euclidean_floor(curr_position, temp_goal_position) >= self.follower_goal_radius:\n",
    "                action, terminate_local = self.local_agent.navigate_local(gt=True)\n",
    "                if terminate_local:\n",
    "                    invalid_edge = True\n",
    "                    break\n",
    "                action = self.local_agent.action_idx_map[action]\n",
    "                prev_position = self.cur_position\n",
    "                prev_local_map = self.local_agent.gt_local_map\n",
    "\n",
    "\n",
    "\n",
    "                prev_obs = obs\n",
    "                prev_rgb = prev_obs['color_sensor'][:, :, :3]\n",
    "                prev_depth = prev_obs['depth_sensor']\n",
    "                \n",
    "\n",
    "#                 obs = self._sim.step(action)\n",
    "#                 obs = controller.pub_cmd(action)\n",
    "                get_robot_obs = False\n",
    "                while not get_robot_obs:\n",
    "                    try:\n",
    "                        obs = controller.pub_cmd(action)\n",
    "                        get_robot_obs = True\n",
    "                    except KeyboardInterrupt:\n",
    "                        print(\"KeyboardInterrupt\")\n",
    "                        break\n",
    "                    except:\n",
    "                        print('Connection error occured')\n",
    "                        pass\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                self.action_step += 1\n",
    "                local_action_cnt += 1\n",
    "                if action == 'move_forward':\n",
    "                    arrive_node = False\n",
    "                    \n",
    "                curr_agent_view, curr_local_map, _, _ = self.local_agent.mapper.get_curr_obsmap(obs['depth_sensor']*100.)\n",
    "\n",
    "                curr_rgb = obs['color_sensor'][:, :, :3]\n",
    "                for _ in range(5):\n",
    "                    est_pos_diff, est_rot_diff, vo_success = self.get_vo_relative_camera_pose(prev_rgb, prev_depth, curr_rgb, action, self.cur_rotation, prev_local_map, curr_local_map)\n",
    "                    if vo_success: break\n",
    "                curr_position = self.cur_position + est_pos_diff\n",
    "                curr_rotation = self.cur_rotation + est_rot_diff\n",
    "                print(f'Step {len(self.vis_traj)} Action {action} vo:{vo_success} pos diff:{est_pos_diff}, rot diff:{np.rad2deg(est_rot_diff[1])}')\n",
    "                print('                          pose {}'.format(obs['pose']))\n",
    "                self.cur_position = curr_position\n",
    "                self.cur_rotation = curr_rotation\n",
    "                \n",
    "                self.path_length += self.dist_euclidean_floor(prev_position, curr_position)\n",
    "\n",
    "\n",
    "\n",
    "                det, det_dist = self.check_close_goal_det(obs['color_sensor'], obs['depth_sensor'], vis=True)\n",
    "\n",
    "#                 pano_obs = self.panoramic_obs(obs, semantic=False)\n",
    "                self.pano_rgb_list.append(obs['rgb_panoramic'])\n",
    "                self.rgb_list.append(obs['color_sensor'])\n",
    "                self.depth_list.append(obs['depth_sensor'])\n",
    "            \n",
    "            \n",
    "            \n",
    "                self.local_agent.gt_new_sim_origin = get_sim_location(curr_position,\n",
    "                                                                      quaternion.from_rotation_vector(curr_rotation))\n",
    "                self.local_agent.update_gt_local_map(obs['depth_sensor'])\n",
    "                \n",
    "\n",
    "                if self.vis_floorplan:\n",
    "                    self.vis_info['cur_position'] = curr_position\n",
    "                    if invalid_edge:\n",
    "                        self.vis_info['mode'] = 'Return to the previous node'\n",
    "                    else:\n",
    "                        self.vis_info['mode'] = 'Exploration'\n",
    "                    vis_local_map = self.local_agent.get_observed_colored_map(gt=True)\n",
    "#                     det_pano, _, _, _, _, _ = self.detector.predicted_img(self.pano_rgb_list[-1], show=True)\n",
    "                    total_frame = self.make_total_frame(det['det_img'], obs['depth_sensor'], \n",
    "                                                        vis_graph_map, vis_local_map, \n",
    "                                                        pano_rgb=self.pano_rgb_list[-1],\n",
    "                                                        info=self.vis_info, frame_num=len(self.vis_traj))\n",
    "                    self.vis_traj.append(total_frame)\n",
    "\n",
    "                if det_dist < self.last_mile_range:\n",
    "                    obs_goal_position = self.get_position_from_pixel(curr_position, curr_rotation, obs['depth_sensor'], det['obj_min_pixel'])\n",
    "                    vis_obs_goal_position = self.get_position_from_pixel(curr_state.position-self.abs_init_position,\n",
    "                                                                         quaternion.as_rotation_vector(curr_state.rotation), obs['depth_sensor'], det['obj_min_pixel'])\n",
    "                    new_goal_obj_det = True\n",
    "                    for cand_goal_idx in range(len(self.goal_obs_consistency['position'])):\n",
    "                        if np.linalg.norm(self.goal_obs_consistency['position'][cand_goal_idx] - obs_goal_position) < 1.0 - self.step_size:\n",
    "                            self.goal_obs_consistency['count'][cand_goal_idx] += 1\n",
    "                            # self.goal_obs_consistency['position'][cand_goal_idx] = obs_goal_position\n",
    "                            self.goal_obs_consistency['position'][cand_goal_idx] = \\\n",
    "                                (self.goal_obs_consistency['position'][cand_goal_idx] * (self.goal_obs_consistency['count'][cand_goal_idx] - 1) + obs_goal_position) / self.goal_obs_consistency['count'][cand_goal_idx]\n",
    "                            self.goal_obs_consistency['vis_position'][cand_goal_idx] = \\\n",
    "                                (self.goal_obs_consistency['vis_position'][cand_goal_idx] * (self.goal_obs_consistency['count'][cand_goal_idx] - 1) + vis_obs_goal_position) / self.goal_obs_consistency['count'][cand_goal_idx]\n",
    "                            new_goal_obj_det = False\n",
    "                            break\n",
    "                    if new_goal_obj_det:\n",
    "                        self.goal_obs_consistency['position'].append(obs_goal_position)\n",
    "                        self.goal_obs_consistency['vis_position'].append(vis_obs_goal_position)\n",
    "                        self.goal_obs_consistency['count'].append(1)\n",
    "\n",
    "\n",
    "                if len(self.goal_obs_consistency['count']) > 0:\n",
    "                    if np.max(self.goal_obs_consistency['count']) >= self.goal_obs_consistency_th:\n",
    "                        last_mile_navi_mode = True\n",
    "                        last_mile_obs = obs\n",
    "                        # last_mile_det = det\n",
    "                        break\n",
    "\n",
    "\n",
    "#                 if obs['collided'] or \\\n",
    "#                         (actcoion == 'move_forward' and np.linalg.norm(prev_position - curr_state.position) < self.step_size * 0.3):\n",
    "                if action == 'move_forward' and np.linalg.norm(prev_position - curr_position) < self.step_size * 0.3:\n",
    "                    self.local_agent.collision = True\n",
    "\n",
    "\n",
    "#                 if arrive_node:\n",
    "#                     ### --- cur_node_position --- ###\n",
    "#                     curr_position = np.array(self.cur_node.pos)\n",
    "#                     self.cur_position = curr_position\n",
    "                    \n",
    "#                     cand_nodes = self.get_cand_node_dirc(self.pano_rgb_list[-1], self.depth_list[-1], curr_position,\n",
    "#                                                          curr_rotation, self.cur_node.vis_pos)\n",
    "#                     # temp_node_num = len(self.graph_map.nodes)\n",
    "#                     self.update_cand_node_to_graph(self.cur_node, cand_nodes)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "#                     # if temp_node_num < len(self.graph_map.nodes):\n",
    "                    #     ## new cand node is added\n",
    "                    #     break\n",
    "        \n",
    "                cand_nodes = self.get_cand_node_dirc(self.pano_rgb_list[-1], self.depth_list[-1], curr_position,\n",
    "                                                     curr_rotation,\n",
    "                                                     np.array(curr_state.position) - np.array(self.abs_init_position))\n",
    "                cur_node_id, _ = self.graph_map.get_nearest_node(curr_position)\n",
    "                self.update_cand_node_to_graph(self.graph_map.node_by_id[cur_node_id], cand_nodes)\n",
    "                \n",
    "                \n",
    "\n",
    "                self.local_agent.gt_new_sim_origin = get_sim_location(curr_position,\n",
    "                                                                      quaternion.from_rotation_vector(curr_rotation))\n",
    "                self.local_agent.update_gt_local_map(obs['depth_sensor'])\n",
    "\n",
    "\n",
    "                if self.vis_floorplan:\n",
    "                    self.visited_positions.append(curr_position)\n",
    "                    vis_graph_map = self.vis_topdown_map_with_captions(self.graph_map,\n",
    "                                                                   curr_node=self.cur_node,\n",
    "                                                                   bias_position=self.abs_init_position,\n",
    "                                                                   curr_position=curr_position,\n",
    "                                                                   curr_goal_node=subgoal_node,\n",
    "                                                                   visited_positions=self.visited_positions)\n",
    "                    vis_local_map = self.local_agent.get_observed_colored_map(gt=True)\n",
    "                    \n",
    "                self.check_pano_goal_det(obs['rgb_panoramic'], self.cur_node, curr_position, curr_rotation, vis=True)\n",
    "#                 curr_position, curr_rotation = self.cur_position, self.cur_rotation\n",
    "                if self.end_episode:\n",
    "                    return self.end_episode\n",
    "\n",
    "                self.end_episode = False\n",
    "\n",
    "\n",
    "                if self.action_step > self.max_step:\n",
    "                    max_action_step = True\n",
    "                    break\n",
    "\n",
    "                if local_action_cnt >= self.max_local_action_trial:\n",
    "                    invalid_edge = True\n",
    "                    break\n",
    "                else:\n",
    "                    invalid_edge = False\n",
    "                    invalid_edge_node = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if max_action_step:\n",
    "                break\n",
    "            if last_mile_navi_mode:\n",
    "                break\n",
    "            if local_action_cnt < self.max_local_action_trial:\n",
    "                invalid_edge = False\n",
    "                invalid_edge_node = []\n",
    "            if invalid_edge:\n",
    "#                 try:\n",
    "#                     self.graph_map.delete_edge(self.cur_node, temp_goal_node)\n",
    "#                     print('invalid edge')\n",
    "#                 except KeyboardInterrupt:\n",
    "#                     print(\"KeyboardInterrupt\")\n",
    "#                     break\n",
    "#                 except:\n",
    "#                     pass\n",
    "                print('invalid node')\n",
    "                self.graph_map.delete_invalid_node(temp_goal_node)\n",
    "                invalid_edge_node.append(temp_goal_node.nodeid)\n",
    "                continue\n",
    "\n",
    "            self.cur_node = temp_goal_node\n",
    "            arrive_node = True\n",
    "            invalid_edge = False\n",
    "            invalid_edge_node = []\n",
    "\n",
    "            # update current arrived node\n",
    "            \n",
    "#             curr_obs = self._sim.get_sensor_observations()\n",
    "#             curr_pano_obs = self.panoramic_obs(curr_obs)\n",
    "#             curr_obs = controller.get_obs()\n",
    "            get_robot_obs = False\n",
    "            while not get_robot_obs:\n",
    "                try:\n",
    "                    curr_obs = controller.get_obs()\n",
    "                    get_robot_obs = True\n",
    "                except KeyboardInterrupt:\n",
    "                    print(\"KeyboardInterrupt\")\n",
    "                    break\n",
    "                except:\n",
    "                    print('Connection error occured')\n",
    "                    pass\n",
    "\n",
    "\n",
    "            \n",
    "            pano_images = self.get_dirc_imgs_from_pano(curr_obs['rgb_panoramic'])\n",
    "            self.check_cand_node_edge(self.cur_node, self.pano_rgb_list[-1], curr_position, curr_rotation)\n",
    "            \n",
    "\n",
    "            pano_image_feat = self.common_sense_model.clip.get_image_feat(pano_images)\n",
    "            cur_heading_idx = int(np.round(-curr_rotation[1] * 180 / np.pi / self.cand_rot_angle)) % self.rot_num\n",
    "            self.graph_map.update_node_goal_category(self.cur_node, self.goal_class_onehot)\n",
    "            for i in range(len(pano_images)):\n",
    "                dirc_head_idx = (cur_heading_idx -5 + i) % self.rot_num\n",
    "                self.graph_map.update_node_clip_feat(self.cur_node, pano_image_feat[i], dirc_head_idx)\n",
    "                torch.set_num_threads(1)\n",
    "                if self.cm_type == 'comet':\n",
    "                    goal_cm_scores, _ = self.common_sense_model.text_image_score(self.goal_place_text_feat,\n",
    "                                                                                 pano_image_feat[i], feat=True,\n",
    "                                                                                 return_only_max=False)\n",
    "                    # goal_cm_scores = torch.softmax(goal_cm_scores, dim=1)\n",
    "                    goal_cm_scores = goal_cm_scores * 0.01\n",
    "                    self.cur_node.update_goal_cm_scores(goal_cm_scores, dirc_head_idx)\n",
    "\n",
    "\n",
    "                elif self.cm_type == 'mp3d':\n",
    "                    goal_cm_scores, _ = self.common_sense_model.text_image_score(self.cand_place_text_feat,\n",
    "                                                                                 pano_image_feat[i], feat=True,\n",
    "                                                                                 return_only_max=False)\n",
    "                    goal_cm_scores = goal_cm_scores[:, :5]\n",
    "\n",
    "                    goal_cm_scores = np.round(np.max(np.exp(goal_cm_scores) / np.sum(np.exp(goal_cm_scores)), axis=1),\n",
    "                                              5)\n",
    "                    weighted_goal_cm_scores = goal_cm_scores * self.cand_category_room_score[\n",
    "                                                                   self.goal_info['category']][\n",
    "                                                               :5]  ## weighted by room category\n",
    "                    self.cur_node.update_goal_cm_scores(weighted_goal_cm_scores, dirc_head_idx)\n",
    "                    \n",
    "                    \n",
    "            self.graph_map.update_node_vis_feat(self.cur_node)\n",
    "#             cm_scores, _ = self.common_sense_model.text_image_score(self.goal_place_text_feat,\n",
    "#                                                                     self.cur_node.vis_feat, feat=True,\n",
    "#                                                                     return_only_max=False)\n",
    "#             cm_score = np.round(np.max(np.exp(cm_scores) / np.sum(np.exp(cm_scores)), axis=1), 5)\n",
    "#             arg_cm_score = np.argmax(cm_scores, axis=1)\n",
    "#             cm_info = {\n",
    "#                 'goal_place_name': self.goal_info['category_place'],\n",
    "#                 'goal_place_feat': self.goal_place_text_feat,\n",
    "#                 'goal_place_score': cm_scores,\n",
    "#             }\n",
    "#             self.graph_map.update_node_cm_score(self.cur_node,\n",
    "#                                                 cm_score[0] * self.goal_info['category_place_score'][\n",
    "#                                                     arg_cm_score[0]],\n",
    "#                                                 cm_name=self.goal_info['category_place'][arg_cm_score[0]]\n",
    "#                                                 , cm_info=cm_info)\n",
    "\n",
    "            self.graph_map.update_node_visited(self.cur_node)\n",
    "            self.graph_map.update_node_feat(self.cur_node)\n",
    "\n",
    "            cand_nodes = self.get_cand_node_dirc(self.pano_rgb_list[-1], self.depth_list[-1], curr_position, curr_rotation, self.cur_node.vis_pos)\n",
    "            self.update_cand_node_to_graph(self.cur_node, cand_nodes)\n",
    "            \n",
    "            ## -- realsense fov -- ##\n",
    "            self.do_explicit_action(self.cur_node, 'turn_left')\n",
    "            self.do_explicit_action(self.cur_node, 'turn_right')\n",
    "            self.do_explicit_action(self.cur_node, 'turn_right')\n",
    "            self.do_explicit_action(self.cur_node, 'turn_left')\n",
    "            #####\n",
    "            \n",
    "            \n",
    "            self.check_pano_goal_det(curr_obs['rgb_panoramic'], self.cur_node, curr_position, curr_rotation,\n",
    "                                     vis=True)\n",
    "            curr_position, curr_rotation = self.cur_position, self.cur_rotation\n",
    "            \n",
    "            ### -- update current position -- ###\n",
    "#             curr_position = np.array(self.cur_node.pos)\n",
    "#             self.cur_position = curr_position\n",
    "            \n",
    "            if self.end_episode:\n",
    "                return\n",
    "\n",
    "            if last_mile_navi_mode:\n",
    "                break\n",
    "\n",
    "            if max_action_step:\n",
    "                break\n",
    "\n",
    "        ### Last mile navigation ###\n",
    "        if last_mile_navi_mode:\n",
    "            self.last_mile_navigation(last_mile_obs)\n",
    "            return\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navi3/.conda/envs/hwing_v1/lib/python3.7/site-packages/transformers/generation/utils.py:1260: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  \"You have modified the pretrained model configuration to control generation. This is a\"\n",
      "/home/navi3/.conda/envs/hwing_v1/lib/python3.7/site-packages/transformers/generation/utils.py:1357: UserWarning: Using `max_length`'s default (24) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n",
      "/home/navi3/.conda/envs/hwing_v1/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630742027/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize runner\n"
     ]
    }
   ],
   "source": [
    "runner = Runner(args, det_COI)\n",
    "\n",
    "runner.epi_num = 16\n",
    "runner.goal_class_idx = 2\n",
    "\n",
    "runner.init_runner()\n",
    "\n",
    "# 'chair',         # 0\n",
    "# 'couch',         # 1\n",
    "# 'potted plant',  # 2\n",
    "# 'bed',           # 3\n",
    "# 'toilet',        # 4\n",
    "# 'tv'             # 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 Action turn_left vo success:True, pos diff:[-0.10875874 -0.03912307  0.00467422], rot diff:29.727889077139864\n",
      "                          pose (-273.7793988810233, 162.97550192067814, -2.988045372677638)\n",
      "Step 2 Action turn_left vo success:True, pos diff:[-0.08313323 -0.0042361   0.04635845], rot diff:30.608839326201327\n",
      "                          pose (-273.77915696566777, 162.97563355167173, -2.4672927216089517)\n",
      "Step 3 Action turn_left vo success:True, pos diff:[-0.075579   -0.00165836  0.0743543 ], rot diff:30.33029105152543\n",
      "                          pose (-273.7796507038234, 162.97491577498565, -1.9477901478843662)\n",
      "Step 4 Action turn_left vo success:True, pos diff:[ 0.00495627 -0.0030624   0.09140978], rot diff:30.391977811829175\n",
      "                          pose (-273.77975188935403, 162.97384598202817, -1.4300452089173898)\n",
      "Step 5 Action turn_left vo success:True, pos diff:[0.05594581 0.00063526 0.08265114], rot diff:29.97937526185257\n",
      "                          pose (-273.7789074939558, 162.97216507513818, -0.9111828398520703)\n",
      "Step 6 Action turn_left vo success:True, pos diff:[0.09171099 0.00350604 0.07227937], rot diff:30.566055646088273\n",
      "                          pose (-273.7785008894923, 162.97166036867677, -0.3905413240121982)\n",
      "Step 7 Action turn_left vo success:True, pos diff:[ 0.09534967 -0.02530307 -0.00335408], rot diff:29.86855700106934\n",
      "                          pose (-273.77842880114093, 162.97157888633757, 0.12931211806851994)\n",
      "Step 8 Action turn_left vo success:True, pos diff:[ 0.0745577   0.0264391  -0.08932528], rot diff:30.23489719140881\n",
      "                          pose (-273.7802234809026, 162.97072014062883, 0.6466516417609913)\n",
      "Step 9 Action turn_left vo success:True, pos diff:[ 0.04315976 -0.01352316 -0.09145548], rot diff:30.4254932838536\n",
      "                          pose (-273.78034922368374, 162.97033119467702, 1.167384113582031)\n",
      "Step 10 Action turn_left vo success:False, pos diff:[0. 0. 0.], rot diff:30.0\n",
      "                          pose (-273.78073626714223, 162.96749565564664, 1.6842614177072104)\n",
      "Step 11 Action turn_left vo success:True, pos diff:[-0.06433728 -0.0004836  -0.09256097], rot diff:30.226047869799984\n",
      "                          pose (-273.7806460020489, 162.96668146622756, 2.2047175614664605)\n",
      "Step 12 Action turn_left vo success:True, pos diff:[-0.10851841  0.01791462 -0.04651814], rot diff:30.01506841500949\n",
      "                          pose (-273.7810868691979, 162.9670244524313, 2.7259071111444397)\n",
      "Step 13 Action turn_left vo:True pos diff:[-0.11168508 -0.03651847 -0.01644241], rot diff:29.751751788204633\n",
      "                          pose (-273.7828153539597, 162.9672763968267, -3.040826153353138)\n",
      "Step 14 Action turn_left vo:True pos diff:[-0.07619466 -0.00639421  0.04303976], rot diff:30.999747289461816\n",
      "                          pose (-273.7822858381568, 162.9674037933711, -2.5187723827875628)\n",
      "Step 15 Action turn_left vo:True pos diff:[-0.04121174  0.0026238   0.1079235 ], rot diff:30.180666722378284\n",
      "                          pose (-273.7828980599904, 162.96659311541546, -1.9964020830106197)\n",
      "Step 16 Action turn_left vo:True pos diff:[0.0292787  0.01677187 0.07773752], rot diff:30.07094620865258\n",
      "                          pose (-273.7830965745936, 162.96194066530134, -1.4787761760807043)\n",
      "Step 17 Action turn_left vo:True pos diff:[ 0.00417299  0.00261236 -0.00276387], rot diff:31.2744255099054\n",
      "                          pose (-273.7818870337065, 162.956364082616, -0.9581989982049968)\n",
      "Step 18 Action move_forward vo:False pos diff:[-0.10564577  0.01712064  0.2259333 ], rot diff:0.0\n",
      "                          pose (-273.63054565117704, 162.75199460668588, -0.9065306867575527)\n",
      "Step 19 Action turn_left vo:True pos diff:[0.09759891 0.00889259 0.04024078], rot diff:30.395998422228207\n",
      "                          pose (-273.62864286001525, 162.75039982195003, -0.3846842420755756)\n",
      "Step 20 Action move_forward vo:False pos diff:[0.02357191 0.01840333 0.24820492], rot diff:0.0\n",
      "                          pose (-273.3888692500596, 162.6594890687536, -0.34091344117438904)\n",
      "Step 21 Action turn_left vo:True pos diff:[ 0.12239799 -0.00090986 -0.01155825], rot diff:30.12226649070011\n",
      "                          pose (-273.38293416062214, 162.65859696869515, 0.1847697746669974)\n",
      "Step 22 Action move_forward vo:False pos diff:[0.14526737 0.01676902 0.20277128], rot diff:0.0\n",
      "                          pose (-273.1332084394453, 162.7108591317617, 0.22964821058972618)\n",
      "Step 23 Action turn_left vo success:True, pos diff:[ 0.07111561 -0.00166931 -0.05633388], rot diff:30.960912189167395\n",
      "                          pose (-273.127787294009, 162.71353633921555, 0.7503641415376006)\n",
      "Step 24 Action turn_right vo success:True, pos diff:[0.02545559 0.00123064 0.08179053], rot diff:-29.49593887197488\n",
      "                          pose (-273.1221782150801, 162.71639130741238, 0.26019291689176605)\n",
      "Step 25 Action turn_right vo success:True, pos diff:[-0.03178815 -0.01430962  0.12001392], rot diff:-28.993080696584755\n",
      "                          pose (-273.11810001211387, 162.71597732119403, -0.23831644173440525)\n",
      "Step 26 Action turn_left vo success:True, pos diff:[ 0.11543522  0.00174334 -0.01504724], rot diff:28.379896187626866\n",
      "                          pose (-273.11941127351247, 162.71573495707693, 0.25653561329885477)\n",
      "Step 27 Action move_forward vo:False pos diff:[0.14825358 0.01647352 0.20062278], rot diff:0.0\n",
      "                          pose (-272.87746631370703, 162.78048868318984, 0.2681186736435528)\n",
      "Step 28 Action move_forward vo:False pos diff:[0.14825358 0.01647352 0.20062278], rot diff:0.0\n",
      "                          pose (-272.6338283749658, 162.8494058754286, 0.282629090475524)\n",
      "Step 29 Action move_forward vo:False pos diff:[0.14825358 0.01647352 0.20062278], rot diff:0.0\n",
      "                          pose (-272.38961742856196, 162.92193427452852, 0.29348041385682233)\n",
      "Step 30 Action turn_left vo success:True, pos diff:[ 1.00685676e-01 -1.12169913e-05 -5.06855008e-02], rot diff:29.320006080903273\n",
      "                          pose (-272.3720285621313, 162.93364382627152, 0.7988360484721344)\n",
      "Step 31 Action turn_right vo success:True, pos diff:[ 0.02697017 -0.00605928  0.1105097 ], rot diff:-28.81402595780143\n",
      "                          pose (-272.3588734208646, 162.94211247054147, 0.30707428680878657)\n",
      "Step 32 Action turn_right vo success:True, pos diff:[-0.02544588  0.00147259  0.11131695], rot diff:-29.7185264975053\n",
      "                          pose (-272.34915279207524, 162.94183285557284, -0.19528461042455758)\n",
      "Step 33 Action turn_left vo success:True, pos diff:[ 0.11949998 -0.00520034 -0.02045843], rot diff:28.47987805869685\n",
      "                          pose (-272.34963647303493, 162.94178655262863, 0.2983314649543871)\n",
      "Step 34 Action turn_right vo:True pos diff:[-0.0528364   0.01106957  0.10611912], rot diff:-29.34983126382671\n",
      "                          pose (-272.34702179471896, 162.9417580873167, -0.20294884633148635)\n",
      "Step 35 Action move_forward vo:False pos diff:[0.02765436 0.01933697 0.24771217], rot diff:0.0\n",
      "                          pose (-272.0998484089813, 162.89001840423728, -0.21571967000880576)\n",
      "Step 36 Action move_forward vo:False pos diff:[0.02765436 0.01933697 0.24771217], rot diff:0.0\n",
      "                          pose (-271.852731775221, 162.8340023720729, -0.23318283303347664)\n",
      "Step 37 Action move_forward vo:False pos diff:[0.02765436 0.01933697 0.24771217], rot diff:0.0\n",
      "                          pose (-271.60582770674995, 162.77346555068908, -0.24904820159886354)\n",
      "Step 38 Action move_forward vo:False pos diff:[0.02765436 0.01933697 0.24771217], rot diff:0.0\n",
      "                          pose (-271.3582657483984, 162.7097179781145, -0.26061190750357843)\n",
      "Step 39 Action turn_left vo success:True, pos diff:[ 0.12052252  0.00049434 -0.00636991], rot diff:29.15252897278904\n",
      "                          pose (-271.3365637570861, 162.70980391140876, 0.2444781440856829)\n",
      "Step 40 Action turn_right vo success:True, pos diff:[-0.04611231 -0.00187986  0.11254463], rot diff:-28.683068957513953\n",
      "                          pose (-271.32231337991755, 162.70957351546176, -0.24900129120100137)\n",
      "Step 41 Action turn_right vo success:True, pos diff:[-0.07211166 -0.01496781  0.08171391], rot diff:-29.477342270163106\n",
      "                          pose (-271.31315609121174, 162.70359516486303, -0.7527552382616487)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 42 Action turn_left vo success:True, pos diff:[0.10926509 0.00227229 0.04006985], rot diff:28.6154398965015\n",
      "                          pose (-271.31246657887885, 162.7024225795255, -0.2614491797226477)\n",
      "Step 43 Action move_forward vo:False pos diff:[0.02603053 0.01970268 0.24785927], rot diff:0.0\n",
      "                          pose (-271.0704426742386, 162.63875425248114, -0.25415202827452577)\n",
      "Step 44 Action move_forward vo:False pos diff:[0.02603053 0.01970268 0.24785927], rot diff:0.0\n",
      "                          pose (-270.8246616775938, 162.5761439723918, -0.2438798778389515)\n",
      "Step 45 Action move_forward vo:False pos diff:[0.02603053 0.01970268 0.24785927], rot diff:0.0\n",
      "                          pose (-270.57717363461364, 162.51510541144106, -0.23749615235381816)\n",
      "Step 46 Action move_forward vo:False pos diff:[0.02603053 0.01970268 0.24785927], rot diff:0.0\n",
      "                          pose (-270.3299781945553, 162.45638448456143, -0.2282171109409057)\n",
      "Step 47 Action turn_left vo success:True, pos diff:[0.10960556 0.00983104 0.02098725], rot diff:29.298962489163053\n",
      "                          pose (-270.306901079805, 162.45755208401204, 0.2738479262057467)\n",
      "Step 48 Action turn_right vo success:True, pos diff:[ 0.01130276 -0.04492323  0.06733197], rot diff:-30.36438015460748\n",
      "                          pose (-270.2898907011503, 162.4580081107814, -0.22073508059193217)\n",
      "Step 49 Action turn_right vo success:True, pos diff:[-0.07819752  0.02198487  0.03866476], rot diff:-29.824473616549657\n",
      "                          pose (-270.2804501882164, 162.45250000000365, -0.7262964296926357)\n",
      "Step 50 Action turn_left vo success:True, pos diff:[0.09206957 0.00851708 0.04178372], rot diff:28.85433177390613\n",
      "                          pose (-270.2795096678117, 162.45186491360363, -0.2329092228859686)\n",
      "Step 51 Action move_forward vo:False pos diff:[0.017522   0.02150803 0.248456  ], rot diff:0.0\n",
      "                          pose (-270.03684797016456, 162.39575901081938, -0.2248683986988378)\n",
      "Step 52 Action move_forward vo:False pos diff:[0.017522   0.02150803 0.248456  ], rot diff:0.0\n",
      "                          pose (-269.7900280958765, 162.34059981272756, -0.21362803802892483)\n",
      "Step 53 Action move_forward vo:False pos diff:[0.017522   0.02150803 0.248456  ], rot diff:0.0\n",
      "                          pose (-269.54214114436616, 162.2871721014012, -0.2094065374089502)\n",
      "Step 54 Action move_forward vo:False pos diff:[0.017522   0.02150803 0.248456  ], rot diff:0.0\n",
      "                          pose (-269.2919024899626, 162.2347921195487, -0.20213662474781247)\n",
      "Step 55 Action turn_left vo success:True, pos diff:[ 0.11816342 -0.00716441  0.02865928], rot diff:29.554589933638912\n",
      "                          pose (-269.2636733867938, 162.23723856326436, 0.3055629356840388)\n",
      "Step 56 Action turn_right vo success:True, pos diff:[-0.03475428 -0.01126921  0.11477389], rot diff:-28.296159089135795\n",
      "                          pose (-269.24496601861404, 162.23910708685804, -0.18959063485230754)\n",
      "Step 57 Action turn_right vo success:True, pos diff:[-0.08353585  0.0015471   0.05352033], rot diff:-29.783345705463198\n",
      "                          pose (-269.2368110961236, 162.23459549295114, -0.6923913090514242)\n",
      "Step 58 Action turn_left vo success:True, pos diff:[ 0.10474394 -0.00280143  0.05366725], rot diff:28.896407833474576\n",
      "                          pose (-269.2357222871238, 162.2340751817512, -0.19479311503835106)\n",
      "Step 59 Action move_forward vo:False pos diff:[0.01902523 0.02078317 0.24840713], rot diff:0.0\n",
      "                          pose (-268.9892682666978, 162.18585007612754, -0.18944745915975994)\n",
      "Step 60 Action move_forward vo:False pos diff:[0.01902523 0.02078317 0.24840713], rot diff:0.0\n",
      "                          pose (-268.74053374818476, 162.1392904603013, -0.18158697426627193)\n",
      "Step 61 Action move_forward vo:False pos diff:[0.01902523 0.02078317 0.24840713], rot diff:0.0\n",
      "                          pose (-268.4907529868394, 162.0942750303438, -0.17343991670519587)\n",
      "Step 62 Action move_forward vo:False pos diff:[0.01902523 0.02078317 0.24840713], rot diff:0.0\n",
      "                          pose (-268.2407613494475, 162.05065614524727, -0.1727936933388641)\n",
      "Step 63 Action turn_left vo success:False, pos diff:[0. 0. 0.], rot diff:30.0\n",
      "                          pose (-268.215476127129, 162.05372373325343, 0.3306796517581266)\n",
      "Step 67 Action turn_right vo success:False, pos diff:[0. 0. 0.], rot diff:-30.0\n",
      "                          pose (-267.8952931793005, 162.46914559145162, 0.39868753378432054)\n",
      "Step 68 Action turn_right vo success:False, pos diff:[0. 0. 0.], rot diff:-30.0\n",
      "                          pose (-267.893856151622, 162.47038020985997, 0.13473763076660727)\n",
      "Step 69 Action turn_left vo success:True, pos diff:[ 0.03818106  0.00358119 -0.02382613], rot diff:33.000264127136376\n",
      "                          pose (-267.89659147782663, 162.46885244564655, 0.6217247945658723)\n",
      "Step 70 Action turn_right vo success:True, pos diff:[-0.04235999 -0.0055226   0.0971787 ], rot diff:-28.746935059395476\n",
      "                          pose (-267.89639370869065, 162.46891862930332, 0.1211037770928094)\n",
      "Step 71 Action turn_left vo success:True, pos diff:[ 0.03211424  0.00967137 -0.02456024], rot diff:33.59335767629782\n",
      "                          pose (-267.8963256282015, 162.46922831685848, 0.6160187800485809)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "runner.do_panoramic_action(runner.cur_node)\n",
    "runner.do_time_steps()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyrealsense2 as rs\n",
    "# frames = controller.pipeline.wait_for_frames()\n",
    "# align = rs.align(rs.stream.color)\n",
    "# aligned_frames = align.process(frames)\n",
    "\n",
    "# color_frame = aligned_frames.get_color_frame() \n",
    "# depth_frame = aligned_frames.get_depth_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intrinsic = frames.get_color_frame().profile.as_video_stream_profile().intrinsics\n",
    "# np.rad2deg(2*math.atan(320/intrinsic.fx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox  6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAloAAAGRCAYAAAC9nB0AAAADv0lEQVR4nO3BMQEAAADCoPVPbQdvoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE4DvksAAZXtY/0AAAAASUVORK5CYII=\" width=\"431.43333333333334\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "obs = controller.get_obs()\n",
    "rgb = obs['color_sensor']\n",
    "img, pred_classes, scores, pred_out, masks, boxes = runner.detector.predicted_img(rgb, show=True)\n",
    "plt.imshow(img)#[50:100,100:150])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox  6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"431.43333333333334\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "obs = controller.get_obs()\n",
    "depth = obs['depth_sensor']\n",
    "runner.local_agent.reset_with_curr_pose(runner.cur_position, runner.cur_rotation)\n",
    "x_gt, y_gt, o_gt = runner.local_agent.get_mapper_pose_from_sim_pose(\n",
    "            runner.local_agent.gt_new_sim_origin,\n",
    "            runner.local_agent.sim_origin,\n",
    "        )\n",
    "runner.local_agent.update_visited_map([runner.local_agent.x_gt, runner.local_agent.y_gt], [x_gt, y_gt], gt=True)\n",
    "\n",
    "runner.local_agent.x_gt, runner.local_agent.y_gt, runner.local_agent.o_gt = x_gt, y_gt, o_gt\n",
    "x, y, o = runner.local_agent.x_gt, runner.local_agent.y_gt, runner.local_agent.o_gt\n",
    "\n",
    "depth_cm = depth * 100.\n",
    "gt_local_map, gt_local_exp_map, _ = runner.local_agent.mapper.update_map(\n",
    "    depth_cm, (x, y, o),\n",
    "    # curr_depth_img, (x, y, o)\n",
    "    gt=True\n",
    ")\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(depth)\n",
    "plt.subplot(122)\n",
    "plt.imshow(gt_local_map, origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "success = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'goal object': 'plant', 'success': 1, 'action step': 71, 'path_length': 10.260117543180462}\n"
     ]
    }
   ],
   "source": [
    "## --- evaluation --- ##\n",
    "result = {\n",
    "    'goal object': runner.goal_info['category'],\n",
    "    'success': success,\n",
    "    'action step': runner.action_step,\n",
    "    'path_length': runner.path_length,\n",
    "}\n",
    "\n",
    "\n",
    "## --- save results --- ##\n",
    "save_dir = f'epi_{runner.epi_num:02d}'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "runner.save_rgbd_video(runner.rgb_list, runner.depth_list, save_dir)\n",
    "\n",
    "with open(f'{save_dir}/graph.pkl', 'wb') as f:\n",
    "    pickle.dump(runner.graph_map, f)\n",
    "\n",
    "cur_goal_obj_category_name = runner.goal_info['category']\n",
    "if runner.vis_floorplan:\n",
    "    runner.save_video(runner.vis_traj, save_dir)\n",
    "    vis_save_dir = save_dir + '/result.png'\n",
    "    runner.save_viewpoint_on_topdown_map(save_dir=vis_save_dir,\n",
    "                                         vis_map=runner.base_map,\n",
    "                                       bias_position=runner.abs_init_position,\n",
    "                                       curr_position=runner.cur_position,\n",
    "                                      curr_goal_position=runner.object_goal_position,\n",
    "                                       result=result)\n",
    "\n",
    "\n",
    "with open(\n",
    "        f'{save_dir}/result.json', 'w') as f:\n",
    "    json.dump(result, f)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.260117543180462"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.path_length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csnav_v630",
   "language": "python",
   "name": "csnav_v630"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
